[
    {
        "model_name": "ALBERT-base",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "642.753999"
    },
    {
        "model_name": "ALBERT-large",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "348.027933"
    },
    {
        "model_name": "ALBERT-xlarge",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "258.516497"
    },
    {
        "model_name": "ALBERT-xxlarge",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "247.786250"
    },
    {
        "model_name": "BERT-base-cased",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "96.979507"
    },
    {
        "model_name": "BERT-base-multilingual-cased",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "395.507289"
    },
    {
        "model_name": "BERT-base-multilingual-uncased",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "590.402767"
    },
    {
        "model_name": "BERT-base-uncased",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "270.747446"
    },
    {
        "model_name": "BERT-large-cased",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "69.370661"
    },
    {
        "model_name": "BERT-large-uncased",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "219.651550"
    },
    {
        "model_name": "BERT-medium-uncased",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "447.845670"
    },
    {
        "model_name": "BERT-mini-uncased",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "1142.427494"
    },
    {
        "model_name": "BERT-small-uncased",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "596.793078"
    },
    {
        "model_name": "BERT-tiny-uncased",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "3911.767791"
    },
    {
        "model_name": "BioGPT",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "5260.252676"
    },
    {
        "model_name": "BioMed-RoBERTa-base",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "203.172978"
    },
    {
        "model_name": "ByT5-base",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "861122.658099"
    },
    {
        "model_name": "ByT5-small",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "451109.226003"
    },
    {
        "model_name": "CamemBERT-base",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "3628.712338"
    },
    {
        "model_name": "Cerebras-GPT-111M",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "3471.056822"
    },
    {
        "model_name": "Cerebras-GPT-256M",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "2478.631145"
    },
    {
        "model_name": "ClinicalBERT",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "1825.319536"
    },
    {
        "model_name": "CodeBERT-base",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "812.971850"
    },
    {
        "model_name": "DistilBERT-base-cased",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "293.093580"
    },
    {
        "model_name": "DistilBERT-base-uncased",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "516.824332"
    },
    {
        "model_name": "DistilGPT-2",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "3236.310653"
    },
    {
        "model_name": "DistilRoBERTa-base",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "117.353602"
    },
    {
        "model_name": "FLAN-T5-base",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "93860.314807"
    },
    {
        "model_name": "FLAN-T5-large",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "523532.468008"
    },
    {
        "model_name": "FLAN-T5-small",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "275099.336488"
    },
    {
        "model_name": "FinBERT",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "1410.070084"
    },
    {
        "model_name": "GPT-2-base",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "1892.837609"
    },
    {
        "model_name": "GPT-2-large",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "1068.605770"
    },
    {
        "model_name": "GPT-2-medium",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "1202.771454"
    },
    {
        "model_name": "GPT-Neo-125M",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "2080.643332"
    },
    {
        "model_name": "GPT-fr-base",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "28415.414844"
    },
    {
        "model_name": "GPT-fr-small",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "22886.306675"
    },
    {
        "model_name": "German-BERT-base-cased",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "22852.649196"
    },
    {
        "model_name": "LongT5-Local-base",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "1007494.749582"
    },
    {
        "model_name": "LongT5-TGlobal-base",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "149213.638756"
    },
    {
        "model_name": "MiniLM-L12-H384-RoBERTa-large",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "868281.655939"
    },
    {
        "model_name": "MiniLM-L12-H384-XLMR-Large",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "857365.854309"
    },
    {
        "model_name": "MiniLM-L6-H384-BERT-base-uncased",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "871385.682026"
    },
    {
        "model_name": "MiniLM-L6-H384-BERT-large-uncased",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "862069.990445"
    },
    {
        "model_name": "MiniLM-L6-H384-RoBERTa-large",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "869922.643151"
    },
    {
        "model_name": "MiniLM-L6-H384-XLMR-Large",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "879455.405491"
    },
    {
        "model_name": "MiniLM-L6-H768-BERT-base-uncased",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "868208.863634"
    },
    {
        "model_name": "MiniLM-L6-H768-BERT-large-uncased",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "868336.732515"
    },
    {
        "model_name": "MiniLM-L6-H768-RoBERTa-large",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "867385.672926"
    },
    {
        "model_name": "MobileBERT-uncased",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "304.754378"
    },
    {
        "model_name": "OPT-125M",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "1475.668606"
    },
    {
        "model_name": "OPT-350M",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "1222.565956"
    },
    {
        "model_name": "PolishGPT-2-large",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "35500.702804"
    },
    {
        "model_name": "PolishGPT-2-medium",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "41052.841551"
    },
    {
        "model_name": "PolishGPT-2-small",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "53725.085546"
    },
    {
        "model_name": "PolishRoBERT-base",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "11642.277032"
    },
    {
        "model_name": "Pythia-160M",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "2251.239175"
    },
    {
        "model_name": "Pythia-160M-deduped",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "2364.066006"
    },
    {
        "model_name": "Pythia-410M",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "1480.095674"
    },
    {
        "model_name": "Pythia-410M-deduped",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "1613.791715"
    },
    {
        "model_name": "Pythia-70M",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "3590.421631"
    },
    {
        "model_name": "Pythia-70M-deduped",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "4024.981693"
    },
    {
        "model_name": "RoBERTa-base",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "55.420173"
    },
    {
        "model_name": "RoBERTa-large",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "40.450487"
    },
    {
        "model_name": "SciBERT-cased",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "756.384204"
    },
    {
        "model_name": "SciBERT-uncased",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "618.044938"
    },
    {
        "model_name": "SportsBERT",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "2220.424098"
    },
    {
        "model_name": "Switch-base-8",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "181.533735"
    },
    {
        "model_name": "T5-base",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "183.758336"
    },
    {
        "model_name": "T5-base-v1.1",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "357557.029866"
    },
    {
        "model_name": "T5-base-v1.1-lm-adapt",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "105618.901398"
    },
    {
        "model_name": "T5-efficient-base",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "195862.369415"
    },
    {
        "model_name": "T5-efficient-large",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "152947.365101"
    },
    {
        "model_name": "T5-efficient-mini",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "450313.692918"
    },
    {
        "model_name": "T5-efficient-small",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "323946.037876"
    },
    {
        "model_name": "T5-efficient-tiny",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "354093.725895"
    },
    {
        "model_name": "T5-large",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "122.312324"
    },
    {
        "model_name": "T5-large-v1.1",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "462866.489654"
    },
    {
        "model_name": "T5-large-v1.1-lm-adapt",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "487320.348454"
    },
    {
        "model_name": "T5-small",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "506.430638"
    },
    {
        "model_name": "T5-small-v1.1",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "341130.296409"
    },
    {
        "model_name": "T5-small-v1.1-lm-adapt",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "286071.476313"
    },
    {
        "model_name": "XLM-100-lang",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "1622.825339"
    },
    {
        "model_name": "XLM-17-lang",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "4390.463873"
    },
    {
        "model_name": "XLM-RoBERTa-base",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "148.267817"
    },
    {
        "model_name": "XLM-RoBERTa-large",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "101.450031"
    },
    {
        "model_name": "XLM-en",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "358714.105811"
    },
    {
        "model_name": "mT5-base",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "1436.107727"
    },
    {
        "model_name": "mT5-large",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "1018.539884"
    },
    {
        "model_name": "mT5-small",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "2755.978437"
    }
]