[
    {
        "model_name": "ALBERT-base",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "1159.747338"
    },
    {
        "model_name": "ALBERT-large",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "633.599299"
    },
    {
        "model_name": "ALBERT-xlarge",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "483.068410"
    },
    {
        "model_name": "ALBERT-xxlarge",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "453.873499"
    },
    {
        "model_name": "BERT-base-cased",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "295.661357"
    },
    {
        "model_name": "BERT-base-multilingual-cased",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "1000.154206"
    },
    {
        "model_name": "BERT-base-multilingual-uncased",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "977.238053"
    },
    {
        "model_name": "BERT-base-uncased",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "484.629860"
    },
    {
        "model_name": "BERT-large-cased",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "219.702688"
    },
    {
        "model_name": "BERT-large-uncased",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "397.674382"
    },
    {
        "model_name": "BERT-medium-uncased",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "752.657049"
    },
    {
        "model_name": "BERT-mini-uncased",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "1758.401608"
    },
    {
        "model_name": "BERT-small-uncased",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "970.519282"
    },
    {
        "model_name": "BERT-tiny-uncased",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "5517.729795"
    },
    {
        "model_name": "BioGPT",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "5962.665494"
    },
    {
        "model_name": "BioMed-RoBERTa-base",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "578.935914"
    },
    {
        "model_name": "ByT5-base",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "853034.846602"
    },
    {
        "model_name": "ByT5-small",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "497594.255131"
    },
    {
        "model_name": "CamemBERT-base",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "7535.989944"
    },
    {
        "model_name": "Cerebras-GPT-111M",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "4031.485025"
    },
    {
        "model_name": "Cerebras-GPT-256M",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "2807.008455"
    },
    {
        "model_name": "ClinicalBERT",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "2652.158097"
    },
    {
        "model_name": "CodeBERT-base",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "1761.849597"
    },
    {
        "model_name": "DistilBERT-base-cased",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "736.543739"
    },
    {
        "model_name": "DistilBERT-base-uncased",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "878.663726"
    },
    {
        "model_name": "DistilGPT-2",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "3174.030488"
    },
    {
        "model_name": "DistilRoBERTa-base",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "357.692876"
    },
    {
        "model_name": "FLAN-T5-base",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "112769.665404"
    },
    {
        "model_name": "FLAN-T5-large",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "586861.805988"
    },
    {
        "model_name": "FLAN-T5-small",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "299802.619484"
    },
    {
        "model_name": "FinBERT",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "2156.393037"
    },
    {
        "model_name": "GPT-2-base",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "2146.616864"
    },
    {
        "model_name": "GPT-2-large",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "1354.241110"
    },
    {
        "model_name": "GPT-2-medium",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "1567.787615"
    },
    {
        "model_name": "GPT-Neo-125M",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "2397.590945"
    },
    {
        "model_name": "GPT-fr-base",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "25793.308892"
    },
    {
        "model_name": "GPT-fr-small",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "21736.437760"
    },
    {
        "model_name": "German-BERT-base-cased",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "32712.027479"
    },
    {
        "model_name": "LongT5-Local-base",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "1009177.616268"
    },
    {
        "model_name": "LongT5-TGlobal-base",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "150175.436570"
    },
    {
        "model_name": "MiniLM-L12-H384-RoBERTa-large",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "868739.016204"
    },
    {
        "model_name": "MiniLM-L12-H384-XLMR-Large",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "869449.990832"
    },
    {
        "model_name": "MiniLM-L6-H384-BERT-base-uncased",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "866334.649496"
    },
    {
        "model_name": "MiniLM-L6-H384-BERT-large-uncased",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "869853.200957"
    },
    {
        "model_name": "MiniLM-L6-H384-RoBERTa-large",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "872454.948791"
    },
    {
        "model_name": "MiniLM-L6-H384-XLMR-Large",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "865221.906194"
    },
    {
        "model_name": "MiniLM-L6-H768-BERT-base-uncased",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "868399.754819"
    },
    {
        "model_name": "MiniLM-L6-H768-BERT-large-uncased",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "864298.183173"
    },
    {
        "model_name": "MiniLM-L6-H768-RoBERTa-large",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "875702.659924"
    },
    {
        "model_name": "MobileBERT-uncased",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "534.612276"
    },
    {
        "model_name": "OPT-125M",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "2087.365901"
    },
    {
        "model_name": "OPT-350M",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "1667.100555"
    },
    {
        "model_name": "PolishGPT-2-large",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "37172.222522"
    },
    {
        "model_name": "PolishGPT-2-medium",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "42697.005684"
    },
    {
        "model_name": "PolishGPT-2-small",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "52431.506962"
    },
    {
        "model_name": "PolishRoBERT-base",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "18909.682287"
    },
    {
        "model_name": "Pythia-160M",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "2556.089236"
    },
    {
        "model_name": "Pythia-160M-deduped",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "2445.449914"
    },
    {
        "model_name": "Pythia-410M",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "1631.827407"
    },
    {
        "model_name": "Pythia-410M-deduped",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "1596.820932"
    },
    {
        "model_name": "Pythia-70M",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "4201.245996"
    },
    {
        "model_name": "Pythia-70M-deduped",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "4167.869977"
    },
    {
        "model_name": "RoBERTa-base",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "179.712358"
    },
    {
        "model_name": "RoBERTa-large",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "132.710332"
    },
    {
        "model_name": "SciBERT-cased",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "1241.479141"
    },
    {
        "model_name": "SciBERT-uncased",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "1030.691621"
    },
    {
        "model_name": "SportsBERT",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "3268.438625"
    },
    {
        "model_name": "Switch-base-8",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "380.946976"
    },
    {
        "model_name": "T5-base",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "486.397718"
    },
    {
        "model_name": "T5-base-v1.1",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "505736.023293"
    },
    {
        "model_name": "T5-base-v1.1-lm-adapt",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "117122.449458"
    },
    {
        "model_name": "T5-efficient-base",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "285584.214537"
    },
    {
        "model_name": "T5-efficient-large",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "260296.691281"
    },
    {
        "model_name": "T5-efficient-mini",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "495829.004645"
    },
    {
        "model_name": "T5-efficient-small",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "423506.029396"
    },
    {
        "model_name": "T5-efficient-tiny",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "403543.144362"
    },
    {
        "model_name": "T5-large",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "335.005404"
    },
    {
        "model_name": "T5-large-v1.1",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "510239.422907"
    },
    {
        "model_name": "T5-large-v1.1-lm-adapt",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "710555.441722"
    },
    {
        "model_name": "T5-small",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "1181.836911"
    },
    {
        "model_name": "T5-small-v1.1",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "503086.924247"
    },
    {
        "model_name": "T5-small-v1.1-lm-adapt",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "348287.097771"
    },
    {
        "model_name": "XLM-100-lang",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "2596.718191"
    },
    {
        "model_name": "XLM-17-lang",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "6512.284676"
    },
    {
        "model_name": "XLM-RoBERTa-base",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "427.705517"
    },
    {
        "model_name": "XLM-RoBERTa-large",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "303.329458"
    },
    {
        "model_name": "XLM-en",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "350122.366624"
    },
    {
        "model_name": "mT5-base",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "2663.200480"
    },
    {
        "model_name": "mT5-large",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "1810.851204"
    },
    {
        "model_name": "mT5-small",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "4511.973725"
    }
]