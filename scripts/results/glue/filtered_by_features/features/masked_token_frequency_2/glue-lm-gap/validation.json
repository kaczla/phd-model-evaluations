[
    {
        "model_name": "ALBERT-base",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "737.210917"
    },
    {
        "model_name": "ALBERT-large",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "408.711827"
    },
    {
        "model_name": "ALBERT-xlarge",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "312.300227"
    },
    {
        "model_name": "ALBERT-xxlarge",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "328.329145"
    },
    {
        "model_name": "BERT-base-cased",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "62.148520"
    },
    {
        "model_name": "BERT-base-multilingual-cased",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "256.308258"
    },
    {
        "model_name": "BERT-base-multilingual-uncased",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "650.920895"
    },
    {
        "model_name": "BERT-base-uncased",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "345.348189"
    },
    {
        "model_name": "BERT-large-cased",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "44.181173"
    },
    {
        "model_name": "BERT-large-uncased",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "284.575117"
    },
    {
        "model_name": "BERT-medium-uncased",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "567.717606"
    },
    {
        "model_name": "BERT-mini-uncased",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "1313.206268"
    },
    {
        "model_name": "BERT-small-uncased",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "718.357010"
    },
    {
        "model_name": "BERT-tiny-uncased",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "4091.621402"
    },
    {
        "model_name": "BioGPT",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "5278.021197"
    },
    {
        "model_name": "BioMed-RoBERTa-base",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "127.507429"
    },
    {
        "model_name": "ByT5-base",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "849446.380510"
    },
    {
        "model_name": "ByT5-small",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "573719.271753"
    },
    {
        "model_name": "CamemBERT-base",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "1701.597180"
    },
    {
        "model_name": "Cerebras-GPT-111M",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "4239.468213"
    },
    {
        "model_name": "Cerebras-GPT-256M",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "2981.043632"
    },
    {
        "model_name": "ClinicalBERT",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "2270.992859"
    },
    {
        "model_name": "CodeBERT-base",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "504.996652"
    },
    {
        "model_name": "DistilBERT-base-cased",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "200.582496"
    },
    {
        "model_name": "DistilBERT-base-uncased",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "607.769065"
    },
    {
        "model_name": "DistilGPT-2",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "5610.151491"
    },
    {
        "model_name": "DistilRoBERTa-base",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "69.748221"
    },
    {
        "model_name": "FLAN-T5-base",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "91304.172208"
    },
    {
        "model_name": "FLAN-T5-large",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "535459.968826"
    },
    {
        "model_name": "FLAN-T5-small",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "287097.172061"
    },
    {
        "model_name": "FinBERT",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "1745.485172"
    },
    {
        "model_name": "GPT-2-base",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "2487.705880"
    },
    {
        "model_name": "GPT-2-large",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "1030.746860"
    },
    {
        "model_name": "GPT-2-medium",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "1098.598591"
    },
    {
        "model_name": "GPT-Neo-125M",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "2280.957176"
    },
    {
        "model_name": "GPT-fr-base",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "31808.837937"
    },
    {
        "model_name": "GPT-fr-small",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "25391.014737"
    },
    {
        "model_name": "German-BERT-base-cased",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "17883.331452"
    },
    {
        "model_name": "LongT5-Local-base",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "1007624.136809"
    },
    {
        "model_name": "LongT5-TGlobal-base",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "177025.983780"
    },
    {
        "model_name": "MiniLM-L12-H384-RoBERTa-large",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "867326.086578"
    },
    {
        "model_name": "MiniLM-L12-H384-XLMR-Large",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "865539.306357"
    },
    {
        "model_name": "MiniLM-L6-H384-BERT-base-uncased",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "872112.699796"
    },
    {
        "model_name": "MiniLM-L6-H384-BERT-large-uncased",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "865952.593205"
    },
    {
        "model_name": "MiniLM-L6-H384-RoBERTa-large",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "868923.228565"
    },
    {
        "model_name": "MiniLM-L6-H384-XLMR-Large",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "871827.036822"
    },
    {
        "model_name": "MiniLM-L6-H768-BERT-base-uncased",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "871859.209386"
    },
    {
        "model_name": "MiniLM-L6-H768-BERT-large-uncased",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "866415.018213"
    },
    {
        "model_name": "MiniLM-L6-H768-RoBERTa-large",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "875349.912835"
    },
    {
        "model_name": "MobileBERT-uncased",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "396.969736"
    },
    {
        "model_name": "OPT-125M",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "955.540270"
    },
    {
        "model_name": "OPT-350M",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "827.725358"
    },
    {
        "model_name": "PolishGPT-2-large",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "32580.347592"
    },
    {
        "model_name": "PolishGPT-2-medium",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "41043.994043"
    },
    {
        "model_name": "PolishGPT-2-small",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "58026.431725"
    },
    {
        "model_name": "PolishRoBERT-base",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "7230.040729"
    },
    {
        "model_name": "Pythia-160M",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "2685.163321"
    },
    {
        "model_name": "Pythia-160M-deduped",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "2886.540831"
    },
    {
        "model_name": "Pythia-410M",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "1843.572517"
    },
    {
        "model_name": "Pythia-410M-deduped",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "2014.214223"
    },
    {
        "model_name": "Pythia-70M",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "4272.719253"
    },
    {
        "model_name": "Pythia-70M-deduped",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "4948.354698"
    },
    {
        "model_name": "RoBERTa-base",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "32.442460"
    },
    {
        "model_name": "RoBERTa-large",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "24.182838"
    },
    {
        "model_name": "SciBERT-cased",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "962.370030"
    },
    {
        "model_name": "SciBERT-uncased",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "767.874883"
    },
    {
        "model_name": "SportsBERT",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "2217.480042"
    },
    {
        "model_name": "Switch-base-8",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "134.419915"
    },
    {
        "model_name": "T5-base",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "101.251100"
    },
    {
        "model_name": "T5-base-v1.1",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "232142.590917"
    },
    {
        "model_name": "T5-base-v1.1-lm-adapt",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "45448.226715"
    },
    {
        "model_name": "T5-efficient-base",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "98088.103112"
    },
    {
        "model_name": "T5-efficient-large",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "63838.500255"
    },
    {
        "model_name": "T5-efficient-mini",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "478495.104024"
    },
    {
        "model_name": "T5-efficient-small",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "239267.820962"
    },
    {
        "model_name": "T5-efficient-tiny",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "382713.089103"
    },
    {
        "model_name": "T5-large",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "68.693503"
    },
    {
        "model_name": "T5-large-v1.1",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "383980.536782"
    },
    {
        "model_name": "T5-large-v1.1-lm-adapt",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "261711.783710"
    },
    {
        "model_name": "T5-small",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "323.395555"
    },
    {
        "model_name": "T5-small-v1.1",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "246052.841306"
    },
    {
        "model_name": "T5-small-v1.1-lm-adapt",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "198419.027655"
    },
    {
        "model_name": "XLM-100-lang",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "9082.850416"
    },
    {
        "model_name": "XLM-17-lang",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "36823.133046"
    },
    {
        "model_name": "XLM-RoBERTa-base",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "66.968632"
    },
    {
        "model_name": "XLM-RoBERTa-large",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "46.169421"
    },
    {
        "model_name": "XLM-en",
        "depth": "1",
        "method": "simple",
        "top_k": "15",
        "PerplexityHashed": "388960.187840"
    },
    {
        "model_name": "mT5-base",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "1181.149622"
    },
    {
        "model_name": "mT5-large",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "727.076246"
    },
    {
        "model_name": "mT5-small",
        "depth": "1",
        "method": "",
        "top_k": "15",
        "PerplexityHashed": "1987.110748"
    }
]