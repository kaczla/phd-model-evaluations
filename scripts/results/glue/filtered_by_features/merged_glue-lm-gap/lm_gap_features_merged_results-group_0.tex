\begin{longtable}{| l | l | l | l | l | l |}
\caption{Porównanie wyników na zadaniu zgadywania zamaskowanego słowa dla poszczególnych podzbiorów na zbiorze zadań GLUE Benchmark - część 1.}\label{table:glue_lm_gap_feature_validation_comparing_0}
    \\
    \hline
    \textbf{LM-GAP} & \textbf{A1} & \textbf{A2} & \textbf{A3} & \textbf{A4} & \textbf{B} \\
    \hline
    \multicolumn{6}{| l |}{\textbf{ALBERT-base}} \\
    \hline
    1575.85 & 1529.23 ↑ & 648.16 ↑ & 542.42 ↑ & 1586.11 ↓ & 1542.97 ↑ \\
    \hline
    \multicolumn{6}{| l |}{\textbf{ALBERT-large}} \\
    \hline
    933.39 & 903.04 ↑ & 355.77 ↑ & 295.15 ↑ & 941.29 ↓ & 917.81 ↑ \\
    \hline
    \multicolumn{6}{| l |}{\textbf{ALBERT-xlarge}} \\
    \hline
    730.84 & 707.67 ↑ & 270.98 ↑ & 222.26 ↑ & 738.9 ↓ & 720.06 ↑ \\
    \hline
    \multicolumn{6}{| l |}{\textbf{ALBERT-xxlarge}} \\
    \hline
    746.99 & 719.5 ↑ & 275.4 ↑ & 226.39 ↑ & 749.99 ↓ & 737.66 ↑ \\
    \hline
    \multicolumn{6}{| l |}{\textbf{BERT-base-cased}} \\
    \hline
    172.1 & 164.84 ↑ & 51.52 ↑ & 40.51 ↑ & 173.56 ↓ & 166.28 ↑ \\
    \hline
    \multicolumn{6}{| l |}{\textbf{BERT-base-multilingual-cased}} \\
    \hline
    635.84 & 613.9 ↑ & 230.35 ↑ & 187.97 ↑ & 641.01 ↓ & 619.05 ↑ \\
    \hline
    \multicolumn{6}{| l |}{\textbf{BERT-base-multilingual-uncased}} \\
    \hline
    1477.05 & 1439.83 ↑ & 601.22 ↑ & 503.82 ↑ & 1495.08 ↓ & 1455.1 ↑ \\
    \hline
    \multicolumn{6}{| l |}{\textbf{BERT-base-uncased}} \\
    \hline
    804.25 & 777.94 ↑ & 299.07 ↑ & 245.75 ↑ & 812.64 ↓ & 786.57 ↑ \\
    \hline
    \multicolumn{6}{| l |}{\textbf{BERT-large-cased}} \\
    \hline
    125.73 & 119.49 ↑ & 35.83 ↑ & 27.81 ↑ & 126.53 ↓ & 121.99 ↑ \\
    \hline
    \multicolumn{6}{| l |}{\textbf{BERT-large-uncased}} \\
    \hline
    670.67 & 648.45 ↑ & 242.36 ↑ & 198.63 ↑ & 679.84 ↓ & 658.87 ↑ \\
    \hline
    \multicolumn{6}{| l |}{\textbf{BERT-medium-uncased}} \\
    \hline
    1260.64 & 1228.64 ↑ & 505.84 ↑ & 421.18 ↑ & 1278.29 ↓ & 1236.22 ↑ \\
    \hline
    \multicolumn{6}{| l |}{\textbf{BERT-mini-uncased}} \\
    \hline
    2714.98 & 2659.6 ↑ & 1215.13 ↑ & 1030.02 ↑ & 2745.96 ↓ & 2659.32 ↑ \\
    \hline
    \multicolumn{6}{| l |}{\textbf{BERT-small-uncased}} \\
    \hline
    1577.66 & 1531.23 ↑ & 651.89 ↑ & 544.56 ↑ & 1590.77 ↓ & 1539.39 ↑ \\
    \hline
    \multicolumn{6}{| l |}{\textbf{BERT-tiny-uncased}} \\
    \hline
    7540.61 & 7404.96 ↑ & 3907.62 ↑ & 3403.75 ↑ & 7594.32 ↓ & 7348.03 ↑ \\
    \hline
    \multicolumn{6}{| l |}{\textbf{BioGPT}} \\
    \hline
    9377.07 & 9178.52 ↑ & 4998.93 ↑ & 4417.22 ↑ & 9460.49 ↓ & 9145.88 ↑ \\
    \hline
    \multicolumn{6}{| l |}{\textbf{BioMed-RoBERTa-base}} \\
    \hline
    312.17 & 298.82 ↑ & 101.98 ↑ & 81.54 ↑ & 312.82 ↓ & 303.83 ↑ \\
    \hline
    \multicolumn{6}{| l |}{\textbf{ByT5-base}} \\
    \hline
    855967.36 & 872042.66 ↓ & 861628.55 ↓ & 862237.19 ↓ & 869979.17 ↓ & 855994.26 ↓ \\
    \hline
    \multicolumn{6}{| l |}{\textbf{ByT5-small}} \\
    \hline
    584584.35 & 590720.81 ↓ & 570755.79 ↑ & 569624.06 ↑ & 589082.89 ↓ & 582655.6 ↑ \\
    \hline
    \multicolumn{6}{| l |}{\textbf{CamemBERT-base}} \\
    \hline
    3469.33 & 3321.97 ↑ & 1574.71 ↑ & 1343.14 ↑ & 3452.46 ↑ & 3435.07 ↑ \\
    \hline
    \multicolumn{6}{| l |}{\textbf{Cerebras-GPT-111M}} \\
    \hline
    7638.67 & 7519.4 ↑ & 3956.45 ↑ & 3474.35 ↑ & 7718.89 ↓ & 7471.99 ↑ \\
    \hline
    \multicolumn{6}{| l |}{\textbf{Cerebras-GPT-256M}} \\
    \hline
    5563.25 & 5472.67 ↑ & 2740.3 ↑ & 2382.82 ↑ & 5592.01 ↓ & 5420.1 ↑ \\
    \hline
    \multicolumn{6}{| l |}{\textbf{ClinicalBERT}} \\
    \hline
    4443.6 & 4388.13 ↑ & 2139.54 ↑ & 1842.47 ↑ & 4522.37 ↓ & 4371.87 ↑ \\
    \hline
    \multicolumn{6}{| l |}{\textbf{CodeBERT-base}} \\
    \hline
    1174.66 & 1141.21 ↑ & 463.14 ↑ & 384.56 ↑ & 1184.14 ↓ & 1146.42 ↑ \\
    \hline
    \multicolumn{6}{| l |}{\textbf{DistilBERT-base-cased}} \\
    \hline
    494.41 & 475.36 ↑ & 172.24 ↑ & 139.76 ↑ & 499.54 ↓ & 482.48 ↑ \\
    \hline
    \multicolumn{6}{| l |}{\textbf{DistilBERT-base-uncased}} \\
    \hline
    1303.64 & 1265.44 ↑ & 524.13 ↑ & 437.06 ↑ & 1317.03 ↓ & 1281.39 ↑ \\
    \hline
    \multicolumn{6}{| l |}{\textbf{DistilGPT-2}} \\
    \hline
    9714.72 & 9541.56 ↑ & 5188.32 ↑ & 4593.84 ↑ & 9796.9 ↓ & 9539.28 ↑ \\
    \hline
    \multicolumn{6}{| l |}{\textbf{DistilRoBERTa-base}} \\
    \hline
    179.69 & 171.22 ↑ & 54.05 ↑ & 42.79 ↑ & 180.83 ↓ & 174.52 ↑ \\
    \hline
    \multicolumn{6}{| l |}{\textbf{FLAN-T5-base}} \\
    \hline
    118104.57 & 117319.63 ↑ & 89557.97 ↑ & 84098.81 ↑ & 117845.98 ↑ & 116685.04 ↑ \\
    \hline
    \multicolumn{6}{| l |}{\textbf{FLAN-T5-large}} \\
    \hline
    562529.86 & 568636.05 ↓ & 538220.96 ↑ & 531078.36 ↑ & 567737.83 ↓ & 559681.67 ↑ \\
    \hline
    \multicolumn{6}{| l |}{\textbf{FLAN-T5-small}} \\
    \hline
    324604.41 & 325222.28 ↓ & 283045.27 ↑ & 276513.11 ↑ & 325169.19 ↓ & 323983.24 ↑ \\
    \hline
    \multicolumn{6}{| l |}{\textbf{FinBERT}} \\
    \hline
    3527.82 & 3452.66 ↑ & 1642.45 ↑ & 1407.76 ↑ & 3571.91 ↓ & 3463.03 ↑ \\
    \hline
    \multicolumn{6}{| l |}{\textbf{GPT-2-base}} \\
    \hline
    4700.32 & 4590.41 ↑ & 2263.39 ↑ & 1968.41 ↑ & 4732.06 ↓ & 4591.47 ↑ \\
    \hline
    \multicolumn{6}{| l |}{\textbf{GPT-2-large}} \\
    \hline
    2127.39 & 2066.13 ↑ & 914.63 ↑ & 773.93 ↑ & 2143.23 ↓ & 2073.49 ↑ \\
    \hline
    \multicolumn{6}{| l |}{\textbf{GPT-2-medium}} \\
    \hline
    2250.94 & 2192.64 ↑ & 977.41 ↑ & 827.85 ↑ & 2269.24 ↓ & 2196.04 ↑ \\
    \hline
    \multicolumn{6}{| l |}{\textbf{GPT-Neo-125M}} \\
    \hline
    4373.95 & 4272.38 ↑ & 2077.48 ↑ & 1801.47 ↑ & 4410.99 ↓ & 4282.06 ↑ \\
    \hline
    \multicolumn{6}{| l |}{\textbf{GPT-fr-base}} \\
    \hline
    46362.46 & 46069.56 ↑ & 31256.71 ↑ & 28730.81 ↑ & 47198.64 ↓ & 45964.86 ↑ \\
    \hline
    \multicolumn{6}{| l |}{\textbf{GPT-fr-small}} \\
    \hline
    38199.7 & 37887.68 ↑ & 24915.88 ↑ & 22766.82 ↑ & 38756.05 ↓ & 37541.58 ↑ \\
    \hline
    \multicolumn{6}{| l |}{\textbf{German-BERT-base-cased}} \\
    \hline
    27859.71 & 26937.53 ↑ & 16973.55 ↑ & 15392.96 ↑ & 27628.06 ↑ & 27387.12 ↑ \\
    \hline
    \multicolumn{6}{| l |}{\textbf{LongT5-Local-base}} \\
    \hline
    1008375.97 & 1008390.79 ↓ & 1010768.41 ↓ & 1007041.76 ↑ & 1011522.17 ↓ & 1007440.56 ↑ \\
    \hline
    \multicolumn{6}{| l |}{\textbf{LongT5-TGlobal-base}} \\
    \hline
    211414.92 & 211087.72 ↑ & 174403.21 ↑ & 168715.36 ↑ & 214113.56 ↓ & 210651.65 ↑ \\
    \hline
    \multicolumn{6}{| l |}{\textbf{MiniLM-L12-H384-RoBERTa-large}} \\
    \hline
    875114.46 & 869079.73 ↑ & 872643.66 ↑ & 868560.89 ↑ & 871699.41 ↑ & 875199.79 ↓ \\
    \hline
    \multicolumn{6}{| l |}{\textbf{MiniLM-L12-H384-XLMR-Large}} \\
    \hline
    876508.94 & 868562.58 ↑ & 867388.49 ↑ & 873992.43 ↑ & 861706.14 ↑ & 875039.68 ↑ \\
    \hline
    \multicolumn{6}{| l |}{\textbf{MiniLM-L6-H384-BERT-base-uncased}} \\
    \hline
    869300.22 & 870611.27 ↓ & 868261.38 ↑ & 876241.84 ↓ & 876174.2 ↓ & 867952.26 ↑ \\
    \hline
    \multicolumn{6}{| l |}{\textbf{MiniLM-L6-H384-BERT-large-uncased}} \\
    \hline
    869819.11 & 873239.0 ↓ & 866567.35 ↑ & 866771.49 ↑ & 872769.02 ↓ & 872670.49 ↓ \\
    \hline
    \multicolumn{6}{| l |}{\textbf{MiniLM-L6-H384-RoBERTa-large}} \\
    \hline
    875278.91 & 869805.48 ↑ & 868920.35 ↑ & 869016.16 ↑ & 868160.3 ↑ & 873238.26 ↑ \\
    \hline
    \multicolumn{6}{| l |}{\textbf{MiniLM-L6-H384-XLMR-Large}} \\
    \hline
    867987.18 & 873359.79 ↓ & 869132.76 ↓ & 863530.63 ↑ & 870340.2 ↓ & 873543.43 ↓ \\
    \hline
    \multicolumn{6}{| l |}{\textbf{MiniLM-L6-H768-BERT-base-uncased}} \\
    \hline
    870332.35 & 867241.85 ↑ & 875317.23 ↓ & 863991.76 ↑ & 869302.12 ↑ & 869616.59 ↑ \\
    \hline
    \multicolumn{6}{| l |}{\textbf{MiniLM-L6-H768-BERT-large-uncased}} \\
    \hline
    873852.3 & 869255.85 ↑ & 870304.29 ↑ & 869381.46 ↑ & 870414.42 ↑ & 863046.39 ↑ \\
    \hline
    \multicolumn{6}{| l |}{\textbf{MiniLM-L6-H768-RoBERTa-large}} \\
    \hline
    869124.25 & 871360.3 ↓ & 877527.26 ↓ & 874363.39 ↓ & 869991.83 ↓ & 868406.45 ↑ \\
    \hline
    \multicolumn{6}{| l |}{\textbf{MobileBERT-uncased}} \\
    \hline
    913.53 & 882.61 ↑ & 348.9 ↑ & 287.3 ↑ & 919.15 ↓ & 892.89 ↑ \\
    \hline
    \multicolumn{6}{| l |}{\textbf{OPT-125M}} \\
    \hline
    2021.62 & 1959.82 ↑ & 857.03 ↑ & 723.62 ↑ & 2033.52 ↓ & 1962.23 ↑ \\
    \hline
    \multicolumn{6}{| l |}{\textbf{OPT-350M}} \\
    \hline
    1767.23 & 1713.28 ↑ & 739.31 ↑ & 620.98 ↑ & 1778.23 ↓ & 1718.79 ↑ \\
    \hline
    \multicolumn{6}{| l |}{\textbf{PolishGPT-2-large}} \\
    \hline
    47767.4 & 47571.12 ↑ & 32278.48 ↑ & 29627.8 ↑ & 48378.53 ↓ & 47130.47 ↑ \\
    \hline
    \multicolumn{6}{| l |}{\textbf{PolishGPT-2-medium}} \\
    \hline
    58446.34 & 58336.94 ↑ & 40534.39 ↑ & 37454.9 ↑ & 59180.0 ↓ & 57507.29 ↑ \\
    \hline
    \multicolumn{6}{| l |}{\textbf{PolishGPT-2-small}} \\
    \hline
    79278.56 & 78911.15 ↑ & 57496.63 ↑ & 53853.13 ↑ & 80679.73 ↓ & 78366.89 ↑ \\
    \hline
    \multicolumn{6}{| l |}{\textbf{PolishRoBERT-base}} \\
    \hline
    12559.89 & 12312.03 ↑ & 6968.33 ↑ & 6188.7 ↑ & 12682.9 ↓ & 12356.59 ↑ \\
    \hline
    \multicolumn{6}{| l |}{\textbf{Pythia-160M}} \\
    \hline
    5102.75 & 4986.75 ↑ & 2480.36 ↑ & 2161.76 ↑ & 5129.86 ↓ & 4973.75 ↑ \\
    \hline
    \multicolumn{6}{| l |}{\textbf{Pythia-160M-deduped}} \\
    \hline
    5450.9 & 5350.46 ↑ & 2683.51 ↑ & 2333.55 ↑ & 5509.57 ↓ & 5346.7 ↑ \\
    \hline
    \multicolumn{6}{| l |}{\textbf{Pythia-410M}} \\
    \hline
    3613.64 & 3535.9 ↑ & 1675.37 ↑ & 1437.69 ↑ & 3642.22 ↓ & 3532.42 ↑ \\
    \hline
    \multicolumn{6}{| l |}{\textbf{Pythia-410M-deduped}} \\
    \hline
    3927.46 & 3839.12 ↑ & 1844.99 ↑ & 1591.03 ↑ & 3961.5 ↓ & 3832.86 ↑ \\
    \hline
    \multicolumn{6}{| l |}{\textbf{Pythia-70M}} \\
    \hline
    7722.04 & 7580.57 ↑ & 4005.12 ↑ & 3518.89 ↑ & 7793.33 ↓ & 7561.22 ↑ \\
    \hline
    \multicolumn{6}{| l |}{\textbf{Pythia-70M-deduped}} \\
    \hline
    8823.05 & 8639.95 ↑ & 4668.46 ↑ & 4122.34 ↑ & 8912.65 ↓ & 8630.8 ↑ \\
    \hline
    \multicolumn{6}{| l |}{\textbf{RoBERTa-base}} \\
    \hline
    91.91 & 87.4 ↑ & 25.21 ↑ & 19.51 ↑ & 92.33 ↓ & 89.53 ↑ \\
    \hline
    \multicolumn{6}{| l |}{\textbf{RoBERTa-large}} \\
    \hline
    69.39 & 65.83 ↑ & 18.23 ↑ & 14.02 ↑ & 69.7 ↓ & 67.61 ↑ \\
    \hline
    \multicolumn{6}{| l |}{\textbf{SciBERT-cased}} \\
    \hline
    2072.33 & 2017.06 ↑ & 891.25 ↑ & 750.3 ↑ & 2094.44 ↓ & 2046.76 ↑ \\
    \hline
    \multicolumn{6}{| l |}{\textbf{SciBERT-uncased}} \\
    \hline
    1681.68 & 1639.14 ↑ & 706.85 ↑ & 589.29 ↑ & 1707.8 ↓ & 1659.28 ↑ \\
    \hline
    \multicolumn{6}{| l |}{\textbf{SportsBERT}} \\
    \hline
    4407.71 & 4318.0 ↑ & 2113.83 ↑ & 1828.87 ↑ & 4468.89 ↓ & 4320.86 ↑ \\
    \hline
    \multicolumn{6}{| l |}{\textbf{Switch-base-8}} \\
    \hline
    349.97 & 335.48 ↑ & 116.69 ↑ & 93.21 ↑ & 351.67 ↓ & 343.57 ↑ \\
    \hline
    \multicolumn{6}{| l |}{\textbf{T5-base}} \\
    \hline
    274.69 & 262.84 ↑ & 88.38 ↑ & 70.29 ↑ & 275.55 ↓ & 268.31 ↑ \\
    \hline
    \multicolumn{6}{| l |}{\textbf{T5-base-v1.1}} \\
    \hline
    267972.65 & 268719.57 ↓ & 229851.42 ↑ & 223030.45 ↑ & 272025.52 ↓ & 264845.68 ↑ \\
    \hline
    \multicolumn{6}{| l |}{\textbf{T5-base-v1.1-lm-adapt}} \\
    \hline
    63737.13 & 63166.38 ↑ & 44342.54 ↑ & 41342.33 ↑ & 64303.44 ↓ & 62637.59 ↑ \\
    \hline
    \multicolumn{6}{| l |}{\textbf{T5-efficient-base}} \\
    \hline
    124430.99 & 124719.4 ↓ & 96366.69 ↑ & 91104.76 ↑ & 126224.37 ↓ & 123225.97 ↑ \\
    \hline
    \multicolumn{6}{| l |}{\textbf{T5-efficient-large}} \\
    \hline
    84932.1 & 84461.16 ↑ & 61804.09 ↑ & 58012.62 ↑ & 86065.67 ↓ & 83445.26 ↑ \\
    \hline
    \multicolumn{6}{| l |}{\textbf{T5-efficient-mini}} \\
    \hline
    510519.38 & 519350.45 ↓ & 485287.27 ↑ & 477116.22 ↑ & 519107.33 ↓ & 506265.78 ↑ \\
    \hline
    \multicolumn{6}{| l |}{\textbf{T5-efficient-small}} \\
    \hline
    277887.45 & 279333.37 ↓ & 240301.77 ↑ & 233182.0 ↑ & 281988.52 ↓ & 274516.7 ↑ \\
    \hline
    \multicolumn{6}{| l |}{\textbf{T5-efficient-tiny}} \\
    \hline
    418979.06 & 424558.13 ↓ & 386306.74 ↑ & 380120.27 ↑ & 427228.77 ↓ & 415802.26 ↑ \\
    \hline
    \multicolumn{6}{| l |}{\textbf{T5-large}} \\
    \hline
    192.32 & 183.15 ↑ & 58.54 ↑ & 46.06 ↑ & 192.73 ↓ & 188.39 ↑ \\
    \hline
    \multicolumn{6}{| l |}{\textbf{T5-large-v1.1}} \\
    \hline
    415089.1 & 421163.26 ↓ & 380762.95 ↑ & 375275.33 ↑ & 424538.88 ↓ & 412997.94 ↑ \\
    \hline
    \multicolumn{6}{| l |}{\textbf{T5-large-v1.1-lm-adapt}} \\
    \hline
    300663.1 & 300843.18 ↓ & 259806.06 ↑ & 252932.3 ↑ & 302012.87 ↓ & 298627.33 ↑ \\
    \hline
    \multicolumn{6}{| l |}{\textbf{T5-small}} \\
    \hline
    782.87 & 756.64 ↑ & 293.86 ↑ & 240.46 ↑ & 790.19 ↓ & 766.86 ↑ \\
    \hline
    \multicolumn{6}{| l |}{\textbf{T5-small-v1.1}} \\
    \hline
    282303.55 & 283960.07 ↓ & 244728.78 ↑ & 237226.21 ↑ & 284781.77 ↓ & 278299.09 ↑ \\
    \hline
    \multicolumn{6}{| l |}{\textbf{T5-small-v1.1-lm-adapt}} \\
    \hline
    233990.72 & 235492.96 ↓ & 197618.41 ↑ & 191926.99 ↑ & 238393.57 ↓ & 232962.66 ↑ \\
    \hline
    \multicolumn{6}{| l |}{\textbf{XLM-100-lang}} \\
    \hline
    15046.79 & 14648.41 ↑ & 8478.35 ↑ & 7584.73 ↑ & 15021.09 ↑ & 14830.67 ↑ \\
    \hline
    \multicolumn{6}{| l |}{\textbf{XLM-17-lang}} \\
    \hline
    52129.25 & 51206.7 ↑ & 35001.25 ↑ & 32342.56 ↑ & 51845.44 ↑ & 51442.67 ↑ \\
    \hline
    \multicolumn{6}{| l |}{\textbf{XLM-RoBERTa-base}} \\
    \hline
    193.88 & 186.13 ↑ & 59.45 ↑ & 47.07 ↑ & 195.33 ↓ & 190.2 ↑ \\
    \hline
    \multicolumn{6}{| l |}{\textbf{XLM-RoBERTa-large}} \\
    \hline
    138.83 & 132.99 ↑ & 40.52 ↑ & 31.78 ↑ & 139.61 ↓ & 136.33 ↑ \\
    \hline
    \multicolumn{6}{| l |}{\textbf{XLM-en}} \\
    \hline
    428281.1 & 425712.02 ↑ & 386244.48 ↑ & 379757.96 ↑ & 427689.99 ↑ & 426390.25 ↑ \\
    \hline
    \multicolumn{6}{| l |}{\textbf{mT5-base}} \\
    \hline
    2491.98 & 2437.39 ↑ & 1103.0 ↑ & 937.04 ↑ & 2522.32 ↓ & 2466.27 ↑ \\
    \hline
    \multicolumn{6}{| l |}{\textbf{mT5-large}} \\
    \hline
    1615.69 & 1570.49 ↑ & 670.65 ↑ & 559.66 ↑ & 1626.7 ↓ & 1596.28 ↑ \\
    \hline
    \multicolumn{6}{| l |}{\textbf{mT5-small}} \\
    \hline
    3976.32 & 3896.98 ↑ & 1878.1 ↑ & 1610.87 ↑ & 4015.61 ↓ & 3923.79 ↑ \\
    \hline
    \multicolumn{6}{| l |}{\textbf{Średnia}} \\
    \hline
    171540.4 & 171860.8 ↓ & 163313.51 ↑ & 161750.81 ↑ & 172247.57 ↓ & 170941.71 ↑ \\
    \hline
\end{longtable}

