\begin{longtable}{| l | l | l | l | l |}
\caption{Porównanie wyników na zadaniu zgadywania zamaskowanego słowa dla poszczególnych podzbiorów na zbiorze zadań GLUE Benchmark - część 3.}\label{table:glue_lm_gap_feature_validation_comparing_2}
    \\
    \hline
    \textbf{LM-GAP} & \textbf{D1} & \textbf{D2} & \textbf{D3} & \textbf{D4} \\
    \hline
    \multicolumn{5}{| l |}{\textbf{ALBERT-base}} \\
    \hline
    1575.85 & 1042.32 ↑ & 225.06 ↑ & 59958.06 ↓ & 614059.2 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{ALBERT-large}} \\
    \hline
    933.39 & 603.69 ↑ & 130.62 ↑ & 40587.88 ↓ & 581610.44 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{ALBERT-xlarge}} \\
    \hline
    730.84 & 466.95 ↑ & 100.87 ↑ & 35509.11 ↓ & 613916.35 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{ALBERT-xxlarge}} \\
    \hline
    746.99 & 504.74 ↑ & 139.43 ↑ & 20573.44 ↓ & 554443.96 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{BERT-base-cased}} \\
    \hline
    172.1 & 95.45 ↑ & 11.66 ↑ & 31229.73 ↓ & 648649.06 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{BERT-base-multilingual-cased}} \\
    \hline
    635.84 & 352.95 ↑ & 30.93 ↑ & 124603.31 ↓ & 660782.04 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{BERT-base-multilingual-uncased}} \\
    \hline
    1477.05 & 920.41 ↑ & 151.0 ↑ & 96491.93 ↓ & 617002.99 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{BERT-base-uncased}} \\
    \hline
    804.25 & 513.68 ↑ & 106.42 ↑ & 39641.53 ↓ & 628889.2 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{BERT-large-cased}} \\
    \hline
    125.73 & 69.81 ↑ & 9.33 ↑ & 20761.9 ↓ & 671036.95 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{BERT-large-uncased}} \\
    \hline
    670.67 & 430.83 ↑ & 93.96 ↑ & 29932.91 ↓ & 627363.33 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{BERT-medium-uncased}} \\
    \hline
    1260.64 & 801.69 ↑ & 146.39 ↑ & 70649.6 ↓ & 741863.91 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{BERT-mini-uncased}} \\
    \hline
    2714.98 & 1719.32 ↑ & 260.22 ↑ & 169661.36 ↓ & 719229.94 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{BERT-small-uncased}} \\
    \hline
    1577.66 & 1002.51 ↑ & 172.66 ↑ & 88555.39 ↓ & 731435.07 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{BERT-tiny-uncased}} \\
    \hline
    7540.61 & 4974.39 ↑ & 716.29 ↑ & 356867.66 ↓ & 790783.21 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{BioGPT}} \\
    \hline
    9377.07 & 6325.32 ↑ & 952.69 ↑ & 361147.67 ↓ & 535426.3 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{BioMed-RoBERTa-base}} \\
    \hline
    312.17 & 183.2 ↑ & 24.46 ↑ & 36666.26 ↓ & 573382.44 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{ByT5-base}} \\
    \hline
    855967.36 & 849555.13 ↑ & 811618.32 ↑ & 926585.23 ↓ & 866141.7 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{ByT5-small}} \\
    \hline
    584584.35 & 575785.57 ↑ & 525072.22 ↑ & 696324.05 ↓ & 724136.47 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{CamemBERT-base}} \\
    \hline
    3469.33 & 2053.83 ↑ & 124.7 ↑ & 459538.19 ↓ & 876848.87 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{Cerebras-GPT-111M}} \\
    \hline
    7638.67 & 5139.51 ↑ & 804.16 ↑ & 300350.95 ↓ & 650841.37 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{Cerebras-GPT-256M}} \\
    \hline
    5563.25 & 3645.1 ↑ & 551.39 ↑ & 259272.58 ↓ & 667994.53 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{ClinicalBERT}} \\
    \hline
    4443.6 & 2854.71 ↑ & 404.96 ↑ & 263223.6 ↓ & 711138.76 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{CodeBERT-base}} \\
    \hline
    1174.66 & 657.52 ↑ & 54.84 ↑ & 230104.54 ↓ & 851860.73 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{DistilBERT-base-cased}} \\
    \hline
    494.41 & 301.22 ↑ & 45.76 ↑ & 40232.07 ↓ & 616948.07 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{DistilBERT-base-uncased}} \\
    \hline
    1303.64 & 890.62 ↑ & 222.74 ↑ & 36510.96 ↓ & 600238.9 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{DistilGPT-2}} \\
    \hline
    9714.72 & 6740.5 ↑ & 1368.29 ↑ & 262291.91 ↓ & 627795.73 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{DistilRoBERTa-base}} \\
    \hline
    179.69 & 106.65 ↑ & 17.96 ↑ & 16010.02 ↓ & 483072.28 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{FLAN-T5-base}} \\
    \hline
    118104.57 & 99071.78 ↑ & 46659.09 ↑ & 524705.18 ↓ & 871948.09 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{FLAN-T5-large}} \\
    \hline
    562529.86 & 543666.47 ↑ & 433408.95 ↑ & 813216.8 ↓ & 886211.46 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{FLAN-T5-small}} \\
    \hline
    324604.41 & 294433.75 ↑ & 174238.54 ↑ & 802012.39 ↓ & 927646.59 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{FinBERT}} \\
    \hline
    3527.82 & 2280.36 ↑ & 318.14 ↑ & 193539.99 ↓ & 615715.97 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{GPT-2-base}} \\
    \hline
    4700.32 & 3098.58 ↑ & 505.8 ↑ & 199652.51 ↓ & 601879.15 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{GPT-2-large}} \\
    \hline
    2127.39 & 1330.42 ↑ & 174.55 ↑ & 147512.8 ↓ & 629274.27 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{GPT-2-medium}} \\
    \hline
    2250.94 & 1415.05 ↑ & 184.89 ↑ & 156298.84 ↓ & 647987.91 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{GPT-Neo-125M}} \\
    \hline
    4373.95 & 2823.1 ↑ & 405.74 ↑ & 233136.29 ↓ & 672276.31 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{GPT-fr-base}} \\
    \hline
    46362.46 & 34250.07 ↑ & 7151.99 ↑ & 799202.04 ↓ & 831228.65 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{GPT-fr-small}} \\
    \hline
    38199.7 & 27621.68 ↑ & 5238.25 ↑ & 793652.81 ↓ & 813796.82 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{German-BERT-base-cased}} \\
    \hline
    27859.71 & 19449.51 ↑ & 2557.03 ↑ & 800057.58 ↓ & 877233.72 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{LongT5-Local-base}} \\
    \hline
    1008375.97 & 1005452.54 ↑ & 1007467.9 ↑ & 1009561.84 ↓ & 1024000.0 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{LongT5-TGlobal-base}} \\
    \hline
    211414.92 & 184266.39 ↑ & 78357.09 ↑ & 831823.63 ↓ & 925297.7 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{MiniLM-L12-H384-RoBERTa-large}} \\
    \hline
    875114.46 & 869746.66 ↑ & 869255.39 ↑ & 867971.99 ↑ & 833469.59 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{MiniLM-L12-H384-XLMR-Large}} \\
    \hline
    876508.94 & 868107.64 ↑ & 865002.76 ↑ & 856384.78 ↑ & 955396.55 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{MiniLM-L6-H384-BERT-base-uncased}} \\
    \hline
    869300.22 & 873302.09 ↓ & 865735.08 ↑ & 875225.77 ↓ & 833055.32 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{MiniLM-L6-H384-BERT-large-uncased}} \\
    \hline
    869819.11 & 865849.27 ↑ & 870020.14 ↓ & 852259.13 ↑ & 955159.44 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{MiniLM-L6-H384-RoBERTa-large}} \\
    \hline
    875278.91 & 868427.59 ↑ & 868860.87 ↑ & 868898.5 ↑ & 923647.06 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{MiniLM-L6-H384-XLMR-Large}} \\
    \hline
    867987.18 & 870835.25 ↓ & 869390.5 ↓ & 864482.33 ↑ & 891513.14 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{MiniLM-L6-H768-BERT-base-uncased}} \\
    \hline
    870332.35 & 875477.45 ↓ & 873166.04 ↓ & 880059.87 ↓ & 989916.26 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{MiniLM-L6-H768-BERT-large-uncased}} \\
    \hline
    873852.3 & 872617.28 ↑ & 874000.86 ↓ & 859844.32 ↑ & 894077.96 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{MiniLM-L6-H768-RoBERTa-large}} \\
    \hline
    869124.25 & 876203.35 ↓ & 877875.19 ↓ & 881919.55 ↓ & 832537.93 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{MobileBERT-uncased}} \\
    \hline
    913.53 & 582.01 ↑ & 114.17 ↑ & 47381.0 ↓ & 692725.92 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{OPT-125M}} \\
    \hline
    2021.62 & 1212.78 ↑ & 124.05 ↑ & 207009.64 ↓ & 704510.3 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{OPT-350M}} \\
    \hline
    1767.23 & 1058.9 ↑ & 111.45 ↑ & 184635.76 ↓ & 693103.88 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{PolishGPT-2-large}} \\
    \hline
    47767.4 & 35183.17 ↑ & 5977.98 ↑ & 851505.54 ↓ & 835476.86 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{PolishGPT-2-medium}} \\
    \hline
    58446.34 & 43951.13 ↑ & 8421.95 ↑ & 852566.1 ↓ & 836861.57 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{PolishGPT-2-small}} \\
    \hline
    79278.56 & 61715.84 ↑ & 14267.96 ↑ & 865399.84 ↓ & 889976.53 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{PolishRoBERT-base}} \\
    \hline
    12559.89 & 8046.75 ↑ & 628.06 ↑ & 815965.1 ↓ & 805776.95 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{Pythia-160M}} \\
    \hline
    5102.75 & 3325.42 ↑ & 478.11 ↑ & 257294.13 ↓ & 716023.42 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{Pythia-160M-deduped}} \\
    \hline
    5450.9 & 3620.27 ↑ & 578.0 ↑ & 231772.17 ↓ & 667899.6 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{Pythia-410M}} \\
    \hline
    3613.64 & 2318.74 ↑ & 347.57 ↑ & 194716.94 ↓ & 711271.06 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{Pythia-410M-deduped}} \\
    \hline
    3927.46 & 2546.82 ↑ & 407.27 ↑ & 190522.56 ↓ & 733570.42 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{Pythia-70M}} \\
    \hline
    7722.04 & 5116.61 ↑ & 723.59 ↑ & 359262.97 ↓ & 678984.1 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{Pythia-70M-deduped}} \\
    \hline
    8823.05 & 5957.08 ↑ & 945.03 ↑ & 325450.45 ↓ & 725395.9 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{RoBERTa-base}} \\
    \hline
    91.91 & 51.53 ↑ & 7.34 ↑ & 13601.31 ↓ & 479300.88 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{RoBERTa-large}} \\
    \hline
    69.39 & 39.14 ↑ & 6.09 ↑ & 9385.32 ↓ & 412110.23 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{SciBERT-cased}} \\
    \hline
    2072.33 & 1339.93 ↑ & 210.5 ↑ & 108020.89 ↓ & 640147.0 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{SciBERT-uncased}} \\
    \hline
    1681.68 & 1084.94 ↑ & 174.74 ↑ & 88185.47 ↓ & 667459.1 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{SportsBERT}} \\
    \hline
    4407.71 & 2714.46 ↑ & 347.84 ↑ & 394201.96 ↓ & 889696.34 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{Switch-base-8}} \\
    \hline
    349.97 & 210.32 ↑ & 43.5 ↑ & 27024.07 ↓ & 702790.9 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{T5-base}} \\
    \hline
    274.69 & 156.19 ↑ & 23.46 ↑ & 37750.47 ↓ & 652216.48 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{T5-base-v1.1}} \\
    \hline
    267972.65 & 240105.82 ↑ & 136515.92 ↑ & 711482.46 ↓ & 759094.83 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{T5-base-v1.1-lm-adapt}} \\
    \hline
    63737.13 & 50112.26 ↑ & 15874.95 ↑ & 599487.5 ↓ & 875880.23 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{T5-efficient-base}} \\
    \hline
    124430.99 & 106263.31 ↑ & 48833.83 ↑ & 554366.4 ↓ & 807858.01 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{T5-efficient-large}} \\
    \hline
    84932.1 & 70072.13 ↑ & 28366.3 ↑ & 520207.33 ↓ & 742391.17 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{T5-efficient-mini}} \\
    \hline
    510519.38 & 490731.54 ↑ & 383386.95 ↑ & 751274.06 ↓ & 772807.31 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{T5-efficient-small}} \\
    \hline
    277887.45 & 250794.15 ↑ & 145853.89 ↑ & 704329.77 ↓ & 773965.3 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{T5-efficient-tiny}} \\
    \hline
    418979.06 & 393482.6 ↑ & 274751.0 ↑ & 759122.41 ↓ & 773129.83 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{T5-large}} \\
    \hline
    192.32 & 109.99 ↑ & 18.54 ↑ & 23883.73 ↓ & 617531.34 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{T5-large-v1.1}} \\
    \hline
    415089.1 & 389995.78 ↑ & 273831.47 ↑ & 707405.51 ↓ & 714707.72 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{T5-large-v1.1-lm-adapt}} \\
    \hline
    300663.1 & 269123.29 ↑ & 153380.75 ↑ & 845292.14 ↓ & 770887.71 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{T5-small}} \\
    \hline
    782.87 & 457.63 ↑ & 56.7 ↑ & 100536.92 ↓ & 599997.25 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{T5-small-v1.1}} \\
    \hline
    282303.55 & 253747.83 ↑ & 147971.87 ↑ & 728991.89 ↓ & 771407.36 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{T5-small-v1.1-lm-adapt}} \\
    \hline
    233990.72 & 204278.73 ↑ & 91613.68 ↑ & 872310.9 ↓ & 892135.17 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{XLM-100-lang}} \\
    \hline
    15046.79 & 11274.96 ↑ & 5674.17 ↑ & 171156.12 ↓ & 820202.25 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{XLM-17-lang}} \\
    \hline
    52129.25 & 43019.98 ↑ & 22064.4 ↑ & 272220.54 ↓ & 738530.4 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{XLM-RoBERTa-base}} \\
    \hline
    193.88 & 98.23 ↑ & 9.62 ↑ & 77181.28 ↓ & 871677.99 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{XLM-RoBERTa-large}} \\
    \hline
    138.83 & 69.47 ↑ & 7.28 ↑ & 57252.8 ↓ & 850639.88 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{XLM-en}} \\
    \hline
    428281.1 & 393862.32 ↑ & 252888.95 ↑ & 867963.04 ↓ & 928153.44 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{mT5-base}} \\
    \hline
    2491.98 & 1468.32 ↑ & 140.45 ↑ & 307836.78 ↓ & 651157.59 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{mT5-large}} \\
    \hline
    1615.69 & 924.21 ↑ & 98.35 ↑ & 235063.07 ↓ & 845762.46 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{mT5-small}} \\
    \hline
    3976.32 & 2420.61 ↑ & 253.81 ↑ & 368727.95 ↓ & 776925.18 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{Średnia}} \\
    \hline
    171540.4 & 165334.55 ↑ & 143878.48 ↑ & 405360.5 ↓ & 743447.79 ↓ \\
    \hline
\end{longtable}

