\begin{longtable}{| l | l | l | l | l |}
\caption{Porównanie wyników na zadaniu zgadywania zamaskowanego słowa dla poszczególnych podzbiorów na zbiorze zadań GLUE Benchmark - część 4.}\label{table:glue_lm_gap_feature_validation_comparing_3}
    \\
    \hline
    \textbf{LM-GAP} & \textbf{E1} & \textbf{E2} & \textbf{E3} & \textbf{E4} \\
    \hline
    \multicolumn{5}{| l |}{\textbf{ALBERT-base}} \\
    \hline
    1575.85 & 1400.57 ↑ & 1140.52 ↑ & 1458.93 ↑ & 1159.75 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{ALBERT-large}} \\
    \hline
    933.39 & 783.73 ↑ & 640.2 ↑ & 822.33 ↑ & 633.6 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{ALBERT-xlarge}} \\
    \hline
    730.84 & 602.45 ↑ & 486.26 ↑ & 631.22 ↑ & 483.07 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{ALBERT-xxlarge}} \\
    \hline
    746.99 & 590.17 ↑ & 481.71 ↑ & 624.14 ↑ & 453.87 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{BERT-base-cased}} \\
    \hline
    172.1 & 408.1 ↓ & 363.14 ↓ & 414.81 ↓ & 295.66 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{BERT-base-multilingual-cased}} \\
    \hline
    635.84 & 1470.79 ↓ & 1522.83 ↓ & 1454.79 ↓ & 1000.15 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{BERT-base-multilingual-uncased}} \\
    \hline
    1477.05 & 1294.67 ↑ & 1126.2 ↑ & 1309.35 ↑ & 977.24 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{BERT-base-uncased}} \\
    \hline
    804.25 & 632.88 ↑ & 533.86 ↑ & 657.21 ↑ & 484.63 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{BERT-large-cased}} \\
    \hline
    125.73 & 301.62 ↓ & 260.81 ↓ & 309.21 ↓ & 219.7 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{BERT-large-uncased}} \\
    \hline
    670.67 & 526.05 ↑ & 434.86 ↑ & 545.83 ↑ & 397.67 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{BERT-medium-uncased}} \\
    \hline
    1260.64 & 1009.71 ↑ & 904.73 ↑ & 1022.11 ↑ & 752.66 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{BERT-mini-uncased}} \\
    \hline
    2714.98 & 2376.58 ↑ & 2230.38 ↑ & 2399.44 ↑ & 1758.4 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{BERT-small-uncased}} \\
    \hline
    1577.66 & 1306.28 ↑ & 1177.79 ↑ & 1325.28 ↑ & 970.52 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{BERT-tiny-uncased}} \\
    \hline
    7540.61 & 6881.77 ↑ & 7077.19 ↑ & 6845.23 ↑ & 5517.73 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{BioGPT}} \\
    \hline
    9377.07 & 8634.59 ↑ & 9482.39 ↓ & 8434.66 ↑ & 5962.67 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{BioMed-RoBERTa-base}} \\
    \hline
    312.17 & 765.12 ↓ & 673.38 ↓ & 778.49 ↓ & 578.94 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{ByT5-base}} \\
    \hline
    855967.36 & 870219.06 ↓ & 877129.03 ↓ & 877026.29 ↓ & 853034.85 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{ByT5-small}} \\
    \hline
    584584.35 & 561975.72 ↑ & 587339.83 ↓ & 552599.37 ↑ & 497594.26 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{CamemBERT-base}} \\
    \hline
    3469.33 & 7851.83 ↓ & 8069.19 ↓ & 8142.13 ↓ & 7535.99 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{Cerebras-GPT-111M}} \\
    \hline
    7638.67 & 5449.7 ↑ & 6181.58 ↑ & 5372.2 ↑ & 4031.49 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{Cerebras-GPT-256M}} \\
    \hline
    5563.25 & 3948.56 ↑ & 4517.29 ↑ & 3862.18 ↑ & 2807.01 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{ClinicalBERT}} \\
    \hline
    4443.6 & 3888.47 ↑ & 3939.48 ↑ & 3826.82 ↑ & 2652.16 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{CodeBERT-base}} \\
    \hline
    1174.66 & 2512.02 ↓ & 2504.09 ↓ & 2491.48 ↓ & 1761.85 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{DistilBERT-base-cased}} \\
    \hline
    494.41 & 1005.06 ↓ & 905.89 ↓ & 1018.34 ↓ & 736.54 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{DistilBERT-base-uncased}} \\
    \hline
    1303.64 & 1115.48 ↑ & 935.03 ↑ & 1156.91 ↑ & 878.66 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{DistilGPT-2}} \\
    \hline
    9714.72 & 4331.89 ↑ & 4905.06 ↑ & 4244.71 ↑ & 3174.03 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{DistilRoBERTa-base}} \\
    \hline
    179.69 & 439.14 ↓ & 363.66 ↓ & 462.52 ↓ & 357.69 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{FLAN-T5-base}} \\
    \hline
    118104.57 & 122768.64 ↓ & 118373.14 ↓ & 125086.33 ↓ & 112769.67 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{FLAN-T5-large}} \\
    \hline
    562529.86 & 592486.36 ↓ & 594254.67 ↓ & 591942.28 ↓ & 586861.81 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{FLAN-T5-small}} \\
    \hline
    324604.41 & 329184.74 ↓ & 335524.16 ↓ & 331051.52 ↓ & 299802.62 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{FinBERT}} \\
    \hline
    3527.82 & 3165.69 ↑ & 3184.29 ↑ & 3161.08 ↑ & 2156.39 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{GPT-2-base}} \\
    \hline
    4700.32 & 2982.99 ↑ & 3218.07 ↑ & 2959.95 ↑ & 2146.62 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{GPT-2-large}} \\
    \hline
    2127.39 & 2029.71 ↑ & 2283.7 ↓ & 2004.5 ↑ & 1354.24 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{GPT-2-medium}} \\
    \hline
    2250.94 & 2308.12 ↓ & 2517.7 ↓ & 2280.67 ↓ & 1567.79 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{GPT-Neo-125M}} \\
    \hline
    4373.95 & 3383.0 ↑ & 3806.95 ↑ & 3318.42 ↑ & 2397.59 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{GPT-fr-base}} \\
    \hline
    46362.46 & 38013.41 ↑ & 42383.66 ↑ & 35979.08 ↑ & 25793.31 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{GPT-fr-small}} \\
    \hline
    38199.7 & 28753.42 ↑ & 31785.55 ↑ & 28004.71 ↑ & 21736.44 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{German-BERT-base-cased}} \\
    \hline
    27859.71 & 32966.24 ↓ & 35559.96 ↓ & 34143.39 ↓ & 32712.03 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{LongT5-Local-base}} \\
    \hline
    1008375.97 & 1009804.48 ↓ & 1008876.91 ↓ & 1008708.86 ↓ & 1009177.62 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{LongT5-TGlobal-base}} \\
    \hline
    211414.92 & 165935.59 ↑ & 192849.38 ↑ & 166060.16 ↑ & 150175.44 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{MiniLM-L12-H384-RoBERTa-large}} \\
    \hline
    875114.46 & 866465.25 ↑ & 869367.71 ↑ & 867825.03 ↑ & 868739.02 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{MiniLM-L12-H384-XLMR-Large}} \\
    \hline
    876508.94 & 872870.7 ↑ & 867920.51 ↑ & 866999.4 ↑ & 869449.99 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{MiniLM-L6-H384-BERT-base-uncased}} \\
    \hline
    869300.22 & 876624.0 ↓ & 872741.52 ↓ & 876029.65 ↓ & 866334.65 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{MiniLM-L6-H384-BERT-large-uncased}} \\
    \hline
    869819.11 & 865006.88 ↑ & 866060.76 ↑ & 863894.58 ↑ & 869853.2 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{MiniLM-L6-H384-RoBERTa-large}} \\
    \hline
    875278.91 & 870982.52 ↑ & 872604.61 ↑ & 875087.43 ↑ & 872454.95 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{MiniLM-L6-H384-XLMR-Large}} \\
    \hline
    867987.18 & 872859.66 ↓ & 869863.44 ↓ & 868106.52 ↓ & 865221.91 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{MiniLM-L6-H768-BERT-base-uncased}} \\
    \hline
    870332.35 & 875701.23 ↓ & 869574.92 ↑ & 873747.62 ↓ & 868399.75 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{MiniLM-L6-H768-BERT-large-uncased}} \\
    \hline
    873852.3 & 871051.01 ↑ & 862873.96 ↑ & 874976.98 ↓ & 864298.18 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{MiniLM-L6-H768-RoBERTa-large}} \\
    \hline
    869124.25 & 872787.31 ↓ & 874486.35 ↓ & 867005.41 ↑ & 875702.66 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{MobileBERT-uncased}} \\
    \hline
    913.53 & 709.56 ↑ & 614.93 ↑ & 724.2 ↑ & 534.61 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{OPT-125M}} \\
    \hline
    2021.62 & 2807.72 ↓ & 3050.19 ↓ & 2811.95 ↓ & 2087.37 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{OPT-350M}} \\
    \hline
    1767.23 & 2383.4 ↓ & 2614.59 ↓ & 2364.01 ↓ & 1667.1 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{PolishGPT-2-large}} \\
    \hline
    47767.4 & 42971.4 ↑ & 47568.65 ↑ & 43430.22 ↑ & 37172.22 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{PolishGPT-2-medium}} \\
    \hline
    58446.34 & 49426.1 ↑ & 54605.08 ↑ & 50000.09 ↑ & 42697.01 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{PolishGPT-2-small}} \\
    \hline
    79278.56 & 59927.65 ↑ & 69893.76 ↑ & 59528.97 ↑ & 52431.51 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{PolishRoBERT-base}} \\
    \hline
    12559.89 & 21480.29 ↓ & 23474.36 ↓ & 21559.01 ↓ & 18909.68 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{Pythia-160M}} \\
    \hline
    5102.75 & 3760.18 ↑ & 4538.04 ↑ & 3654.95 ↑ & 2556.09 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{Pythia-160M-deduped}} \\
    \hline
    5450.9 & 3557.78 ↑ & 4163.36 ↑ & 3462.33 ↑ & 2445.45 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{Pythia-410M}} \\
    \hline
    3613.64 & 2532.93 ↑ & 3131.48 ↑ & 2444.31 ↑ & 1631.83 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{Pythia-410M-deduped}} \\
    \hline
    3927.46 & 2448.6 ↑ & 3000.73 ↑ & 2393.82 ↑ & 1596.82 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{Pythia-70M}} \\
    \hline
    7722.04 & 6025.74 ↑ & 7257.92 ↑ & 5836.58 ↑ & 4201.25 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{Pythia-70M-deduped}} \\
    \hline
    8823.05 & 5844.77 ↑ & 6549.51 ↑ & 5731.87 ↑ & 4167.87 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{RoBERTa-base}} \\
    \hline
    91.91 & 229.14 ↓ & 187.01 ↓ & 240.96 ↓ & 179.71 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{RoBERTa-large}} \\
    \hline
    69.39 & 168.03 ↓ & 135.82 ↓ & 178.83 ↓ & 132.71 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{SciBERT-cased}} \\
    \hline
    2072.33 & 1750.91 ↑ & 1648.44 ↑ & 1749.22 ↑ & 1241.48 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{SciBERT-uncased}} \\
    \hline
    1681.68 & 1408.76 ↑ & 1319.7 ↑ & 1429.23 ↑ & 1030.69 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{SportsBERT}} \\
    \hline
    4407.71 & 4459.37 ↓ & 4014.49 ↑ & 4559.59 ↓ & 3268.44 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{Switch-base-8}} \\
    \hline
    349.97 & 463.61 ↓ & 370.02 ↓ & 488.52 ↓ & 380.95 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{T5-base}} \\
    \hline
    274.69 & 618.56 ↓ & 513.77 ↓ & 642.83 ↓ & 486.4 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{T5-base-v1.1}} \\
    \hline
    267972.65 & 507178.3 ↓ & 504904.93 ↓ & 504247.65 ↓ & 505736.02 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{T5-base-v1.1-lm-adapt}} \\
    \hline
    63737.13 & 131605.89 ↓ & 139123.7 ↓ & 131068.37 ↓ & 117122.45 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{T5-efficient-base}} \\
    \hline
    124430.99 & 283962.21 ↓ & 257484.27 ↓ & 291539.53 ↓ & 285584.21 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{T5-efficient-large}} \\
    \hline
    84932.1 & 232621.33 ↓ & 199813.27 ↓ & 246430.57 ↓ & 260296.69 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{T5-efficient-mini}} \\
    \hline
    510519.38 & 504278.2 ↑ & 507155.7 ↑ & 503006.61 ↑ & 495829.0 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{T5-efficient-small}} \\
    \hline
    277887.45 & 434987.59 ↓ & 437413.89 ↓ & 439334.12 ↓ & 423506.03 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{T5-efficient-tiny}} \\
    \hline
    418979.06 & 409699.41 ↑ & 417306.78 ↑ & 420369.21 ↓ & 403543.14 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{T5-large}} \\
    \hline
    192.32 & 419.77 ↓ & 339.54 ↓ & 440.01 ↓ & 335.01 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{T5-large-v1.1}} \\
    \hline
    415089.1 & 509299.43 ↓ & 507789.62 ↓ & 511373.9 ↓ & 510239.42 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{T5-large-v1.1-lm-adapt}} \\
    \hline
    300663.1 & 696701.24 ↓ & 692604.9 ↓ & 698840.79 ↓ & 710555.44 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{T5-small}} \\
    \hline
    782.87 & 1572.65 ↓ & 1394.95 ↓ & 1589.18 ↓ & 1181.84 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{T5-small-v1.1}} \\
    \hline
    282303.55 & 506284.72 ↓ & 507613.11 ↓ & 509590.46 ↓ & 503086.92 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{T5-small-v1.1-lm-adapt}} \\
    \hline
    233990.72 & 391192.98 ↓ & 416433.2 ↓ & 383512.9 ↓ & 348287.1 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{XLM-100-lang}} \\
    \hline
    15046.79 & 8441.52 ↑ & 11712.23 ↑ & 7149.62 ↑ & 2596.72 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{XLM-17-lang}} \\
    \hline
    52129.25 & 28711.12 ↑ & 50631.44 ↑ & 23689.73 ↑ & 6512.28 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{XLM-RoBERTa-base}} \\
    \hline
    193.88 & 514.55 ↓ & 433.79 ↓ & 534.71 ↓ & 427.71 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{XLM-RoBERTa-large}} \\
    \hline
    138.83 & 356.05 ↓ & 294.57 ↓ & 375.6 ↓ & 303.33 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{XLM-en}} \\
    \hline
    428281.1 & 360821.76 ↑ & 377029.72 ↑ & 358048.95 ↑ & 350122.37 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{mT5-base}} \\
    \hline
    2491.98 & 3465.53 ↓ & 3428.87 ↓ & 3451.95 ↓ & 2663.2 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{mT5-large}} \\
    \hline
    1615.69 & 1986.24 ↓ & 1736.95 ↓ & 2092.51 ↓ & 1810.85 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{mT5-small}} \\
    \hline
    3976.32 & 5264.62 ↓ & 4858.49 ↓ & 5481.88 ↓ & 4511.97 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{Średnia}} \\
    \hline
    171540.4 & 187802.14 ↓ & 188928.82 ↓ & 187922.33 ↓ & 184204.31 ↓ \\
    \hline
\end{longtable}

