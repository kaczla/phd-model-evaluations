\begin{longtable}{| l | l | l | l | l |}
\caption{Porównanie wyników na zadaniu zgadywania zamaskowanego słowa dla poszczególnych podzbiorów na zbiorze zadań GLUE Benchmark - część 2.}\label{table:glue_lm_gap_feature_validation_comparing_1}
    \\
    \hline
    \textbf{LM-GAP} & \textbf{C1} & \textbf{C2} & \textbf{C3} & \textbf{C4} \\
    \hline
    \multicolumn{5}{| l |}{\textbf{ALBERT-base}} \\
    \hline
    1575.85 & 1176.52 ↑ & 737.21 ↑ & 360.74 ↑ & 246.05 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{ALBERT-large}} \\
    \hline
    933.39 & 677.49 ↑ & 408.71 ↑ & 192.55 ↑ & 132.19 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{ALBERT-xlarge}} \\
    \hline
    730.84 & 526.43 ↑ & 312.3 ↑ & 143.67 ↑ & 98.43 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{ALBERT-xxlarge}} \\
    \hline
    746.99 & 539.04 ↑ & 328.33 ↑ & 167.9 ↑ & 122.14 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{BERT-base-cased}} \\
    \hline
    172.1 & 115.75 ↑ & 62.15 ↑ & 24.13 ↑ & 15.21 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{BERT-base-multilingual-cased}} \\
    \hline
    635.84 & 452.15 ↑ & 256.31 ↑ & 95.75 ↑ & 56.93 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{BERT-base-multilingual-uncased}} \\
    \hline
    1477.05 & 1094.1 ↑ & 650.92 ↑ & 274.45 ↑ & 177.46 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{BERT-base-uncased}} \\
    \hline
    804.25 & 580.65 ↑ & 345.35 ↑ & 158.83 ↑ & 107.31 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{BERT-large-cased}} \\
    \hline
    125.73 & 83.38 ↑ & 44.18 ↑ & 17.63 ↑ & 11.35 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{BERT-large-uncased}} \\
    \hline
    670.67 & 480.86 ↑ & 284.58 ↑ & 132.2 ↑ & 90.97 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{BERT-medium-uncased}} \\
    \hline
    1260.64 & 931.55 ↑ & 567.72 ↑ & 257.93 ↑ & 170.25 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{BERT-mini-uncased}} \\
    \hline
    2714.98 & 2070.32 ↑ & 1313.21 ↑ & 592.04 ↑ & 374.47 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{BERT-small-uncased}} \\
    \hline
    1577.66 & 1172.21 ↑ & 718.36 ↑ & 325.46 ↑ & 212.13 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{BERT-tiny-uncased}} \\
    \hline
    7540.61 & 6007.46 ↑ & 4091.62 ↑ & 1968.84 ↑ & 1268.3 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{BioGPT}} \\
    \hline
    9377.07 & 7557.93 ↑ & 5278.02 ↑ & 2629.37 ↑ & 1729.76 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{BioMed-RoBERTa-base}} \\
    \hline
    312.17 & 219.05 ↑ & 127.51 ↑ & 54.72 ↑ & 34.29 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{ByT5-base}} \\
    \hline
    855967.36 & 851368.96 ↑ & 849446.38 ↑ & 834120.22 ↑ & 828762.06 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{ByT5-small}} \\
    \hline
    584584.35 & 581787.69 ↑ & 573719.27 ↑ & 557099.79 ↑ & 548891.81 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{CamemBERT-base}} \\
    \hline
    3469.33 & 2670.77 ↑ & 1701.6 ↑ & 711.16 ↑ & 416.37 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{Cerebras-GPT-111M}} \\
    \hline
    7638.67 & 6131.83 ↑ & 4239.47 ↑ & 2122.61 ↑ & 1409.56 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{Cerebras-GPT-256M}} \\
    \hline
    5563.25 & 4383.49 ↑ & 2981.04 ↑ & 1461.28 ↑ & 969.57 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{ClinicalBERT}} \\
    \hline
    4443.6 & 3470.29 ↑ & 2270.99 ↑ & 1028.47 ↑ & 649.75 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{CodeBERT-base}} \\
    \hline
    1174.66 & 858.33 ↑ & 505.0 ↑ & 188.69 ↑ & 106.99 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{DistilBERT-base-cased}} \\
    \hline
    494.41 & 347.47 ↑ & 200.58 ↑ & 86.71 ↑ & 56.45 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{DistilBERT-base-uncased}} \\
    \hline
    1303.64 & 970.36 ↑ & 607.77 ↑ & 314.15 ↑ & 224.39 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{DistilGPT-2}} \\
    \hline
    9714.72 & 7881.33 ↑ & 5610.15 ↑ & 3009.27 ↑ & 2130.84 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{DistilRoBERTa-base}} \\
    \hline
    179.69 & 122.41 ↑ & 69.75 ↑ & 32.07 ↑ & 21.73 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{FLAN-T5-base}} \\
    \hline
    118104.57 & 107276.75 ↑ & 91304.17 ↑ & 68484.64 ↑ & 58190.34 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{FLAN-T5-large}} \\
    \hline
    562529.86 & 554504.3 ↑ & 535459.97 ↑ & 507436.11 ↑ & 488646.58 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{FLAN-T5-small}} \\
    \hline
    324604.41 & 309746.65 ↑ & 287097.17 ↑ & 242739.22 ↑ & 221811.75 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{FinBERT}} \\
    \hline
    3527.82 & 2725.39 ↑ & 1745.49 ↑ & 759.98 ↑ & 472.55 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{GPT-2-base}} \\
    \hline
    4700.32 & 3699.96 ↑ & 2487.71 ↑ & 1229.02 ↑ & 820.96 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{GPT-2-large}} \\
    \hline
    2127.39 & 1615.63 ↑ & 1030.75 ↑ & 468.11 ↑ & 302.86 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{GPT-2-medium}} \\
    \hline
    2250.94 & 1714.07 ↑ & 1098.6 ↑ & 497.29 ↑ & 319.92 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{GPT-Neo-125M}} \\
    \hline
    4373.95 & 3417.93 ↑ & 2280.96 ↑ & 1094.1 ↑ & 715.82 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{GPT-fr-base}} \\
    \hline
    46362.46 & 40309.21 ↑ & 31808.84 ↑ & 19583.59 ↑ & 14430.65 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{GPT-fr-small}} \\
    \hline
    38199.7 & 32925.05 ↑ & 25391.01 ↑ & 15032.23 ↑ & 10795.72 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{German-BERT-base-cased}} \\
    \hline
    27859.71 & 23708.37 ↑ & 17883.33 ↑ & 10078.47 ↑ & 6965.73 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{LongT5-Local-base}} \\
    \hline
    1008375.97 & 1006912.24 ↑ & 1007624.14 ↑ & 1006988.8 ↑ & 1007293.23 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{LongT5-TGlobal-base}} \\
    \hline
    211414.92 & 198535.57 ↑ & 177025.98 ↑ & 139318.63 ↑ & 119208.02 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{MiniLM-L12-H384-RoBERTa-large}} \\
    \hline
    875114.46 & 875244.35 ↓ & 867326.09 ↑ & 865754.69 ↑ & 865822.19 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{MiniLM-L12-H384-XLMR-Large}} \\
    \hline
    876508.94 & 862599.26 ↑ & 865539.31 ↑ & 874568.91 ↑ & 871439.05 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{MiniLM-L6-H384-BERT-base-uncased}} \\
    \hline
    869300.22 & 875771.57 ↓ & 872112.7 ↓ & 867274.65 ↑ & 867698.07 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{MiniLM-L6-H384-BERT-large-uncased}} \\
    \hline
    869819.11 & 863160.07 ↑ & 865952.59 ↑ & 872014.77 ↓ & 869473.32 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{MiniLM-L6-H384-RoBERTa-large}} \\
    \hline
    875278.91 & 867652.34 ↑ & 868923.23 ↑ & 869118.74 ↑ & 876715.55 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{MiniLM-L6-H384-XLMR-Large}} \\
    \hline
    867987.18 & 877433.09 ↓ & 871827.04 ↓ & 872363.2 ↓ & 866076.5 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{MiniLM-L6-H768-BERT-base-uncased}} \\
    \hline
    870332.35 & 874935.37 ↓ & 871859.21 ↓ & 864225.13 ↑ & 869828.09 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{MiniLM-L6-H768-BERT-large-uncased}} \\
    \hline
    873852.3 & 867620.85 ↑ & 866415.02 ↑ & 874992.04 ↓ & 868827.95 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{MiniLM-L6-H768-RoBERTa-large}} \\
    \hline
    869124.25 & 869160.36 ↓ & 875349.91 ↓ & 877095.96 ↓ & 879153.75 ↓ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{MobileBERT-uncased}} \\
    \hline
    913.53 & 662.54 ↑ & 396.97 ↑ & 180.93 ↑ & 121.42 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{OPT-125M}} \\
    \hline
    2021.62 & 1519.57 ↑ & 955.54 ↑ & 409.77 ↑ & 252.39 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{OPT-350M}} \\
    \hline
    1767.23 & 1322.85 ↑ & 827.73 ↑ & 354.29 ↑ & 219.8 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{PolishGPT-2-large}} \\
    \hline
    47767.4 & 41734.82 ↑ & 32580.35 ↑ & 20093.07 ↑ & 14583.43 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{PolishGPT-2-medium}} \\
    \hline
    58446.34 & 51565.22 ↑ & 41043.99 ↑ & 26025.14 ↑ & 19333.91 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{PolishGPT-2-small}} \\
    \hline
    79278.56 & 71148.89 ↑ & 58026.43 ↑ & 38654.79 ↑ & 29638.24 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{PolishRoBERT-base}} \\
    \hline
    12559.89 & 10218.4 ↑ & 7230.04 ↑ & 3541.38 ↑ & 2256.88 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{Pythia-160M}} \\
    \hline
    5102.75 & 4006.92 ↑ & 2685.16 ↑ & 1288.1 ↑ & 841.69 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{Pythia-160M-deduped}} \\
    \hline
    5450.9 & 4288.57 ↑ & 2886.54 ↑ & 1419.11 ↑ & 949.29 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{Pythia-410M}} \\
    \hline
    3613.64 & 2801.83 ↑ & 1843.57 ↑ & 883.85 ↑ & 584.83 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{Pythia-410M-deduped}} \\
    \hline
    3927.46 & 3044.82 ↑ & 2014.21 ↑ & 986.61 ↑ & 661.85 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{Pythia-70M}} \\
    \hline
    7722.04 & 6195.07 ↑ & 4272.72 ↑ & 2092.26 ↑ & 1374.77 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{Pythia-70M-deduped}} \\
    \hline
    8823.05 & 7097.22 ↑ & 4948.35 ↑ & 2482.56 ↑ & 1667.49 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{RoBERTa-base}} \\
    \hline
    91.91 & 60.48 ↑ & 32.44 ↑ & 13.27 ↑ & 8.61 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{RoBERTa-large}} \\
    \hline
    69.39 & 45.36 ↑ & 24.18 ↑ & 10.13 ↑ & 6.74 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{SciBERT-cased}} \\
    \hline
    2072.33 & 1555.88 ↑ & 962.37 ↑ & 410.83 ↑ & 261.97 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{SciBERT-uncased}} \\
    \hline
    1681.68 & 1254.03 ↑ & 767.87 ↑ & 325.85 ↑ & 208.18 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{SportsBERT}} \\
    \hline
    4407.71 & 3432.78 ↑ & 2217.48 ↑ & 951.36 ↑ & 580.87 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{Switch-base-8}} \\
    \hline
    349.97 & 242.31 ↑ & 134.42 ↑ & 58.04 ↑ & 40.48 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{T5-base}} \\
    \hline
    274.69 & 187.27 ↑ & 101.25 ↑ & 39.39 ↑ & 25.4 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{T5-base-v1.1}} \\
    \hline
    267972.65 & 253595.85 ↑ & 232142.59 ↑ & 203983.1 ↑ & 183037.82 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{T5-base-v1.1-lm-adapt}} \\
    \hline
    63737.13 & 56334.41 ↑ & 45448.23 ↑ & 30442.93 ↑ & 24152.89 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{T5-efficient-base}} \\
    \hline
    124430.99 & 114066.47 ↑ & 98088.1 ↑ & 76742.54 ↑ & 64382.5 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{T5-efficient-large}} \\
    \hline
    84932.1 & 75844.05 ↑ & 63838.5 ↑ & 47619.79 ↑ & 39389.01 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{T5-efficient-mini}} \\
    \hline
    510519.38 & 498422.41 ↑ & 478495.1 ↑ & 460157.57 ↑ & 437418.28 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{T5-efficient-small}} \\
    \hline
    277887.45 & 262162.52 ↑ & 239267.82 ↑ & 210040.92 ↑ & 189841.84 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{T5-efficient-tiny}} \\
    \hline
    418979.06 & 404825.75 ↑ & 382713.09 ↑ & 354505.0 ↑ & 331172.9 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{T5-large}} \\
    \hline
    192.32 & 129.25 ↑ & 68.69 ↑ & 27.23 ↑ & 18.2 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{T5-large-v1.1}} \\
    \hline
    415089.1 & 403055.9 ↑ & 383980.54 ↑ & 360621.13 ↑ & 339685.19 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{T5-large-v1.1-lm-adapt}} \\
    \hline
    300663.1 & 285479.84 ↑ & 261711.78 ↑ & 220267.29 ↑ & 195751.4 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{T5-small}} \\
    \hline
    782.87 & 562.82 ↑ & 323.4 ↑ & 125.49 ↑ & 77.47 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{T5-small-v1.1}} \\
    \hline
    282303.55 & 266283.8 ↑ & 246052.84 ↑ & 214542.42 ↑ & 192990.77 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{T5-small-v1.1-lm-adapt}} \\
    \hline
    233990.72 & 220624.36 ↑ & 198419.03 ↑ & 157170.53 ↑ & 135273.51 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{XLM-100-lang}} \\
    \hline
    15046.79 & 12473.35 ↑ & 9082.85 ↑ & 5517.28 ↑ & 4636.52 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{XLM-17-lang}} \\
    \hline
    52129.25 & 45910.44 ↑ & 36823.13 ↑ & 27125.47 ↑ & 23983.24 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{XLM-RoBERTa-base}} \\
    \hline
    193.88 & 130.44 ↑ & 66.97 ↑ & 20.73 ↑ & 11.96 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{XLM-RoBERTa-large}} \\
    \hline
    138.83 & 91.97 ↑ & 46.17 ↑ & 14.19 ↑ & 8.4 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{XLM-en}} \\
    \hline
    428281.1 & 411967.15 ↑ & 388960.19 ↑ & 343947.84 ↑ & 316329.82 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{mT5-base}} \\
    \hline
    2491.98 & 1888.5 ↑ & 1181.15 ↑ & 489.52 ↑ & 301.71 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{mT5-large}} \\
    \hline
    1615.69 & 1197.47 ↑ & 727.08 ↑ & 291.61 ↑ & 181.38 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{mT5-small}} \\
    \hline
    3976.32 & 3073.11 ↑ & 1987.11 ↑ & 861.17 ↑ & 541.59 ↑ \\
    \hline
    \multicolumn{5}{| l |}{\textbf{Średnia}} \\
    \hline
    171540.4 & 168165.01 ↑ & 163308.86 ↑ & 156371.37 ↑ & 152292.22 ↑ \\
    \hline
\end{longtable}

