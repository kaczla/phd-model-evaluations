\begin{longtable}{| l | l | l | l | l | l | l | l | l | l | l | l |}
\caption{Wyniki dostrojonych neuronowych modeli języka na zbiorze walidacyjnym na zbiorze zadań GLUE Benchmark.}\label{table:glue_score_validation}
    \\
    \hline
    \rotatebox{90}{\textbf{loss}} & \rotatebox{90}{\textbf{LM-GAP}} & \rotatebox{90}{\textbf{CoLA}} & \rotatebox{90}{\textbf{MNLI-m}} & \rotatebox{90}{\textbf{MNLI-mm}} & \rotatebox{90}{\textbf{MRPC}} & \rotatebox{90}{\textbf{QNLI}} & \rotatebox{90}{\textbf{QQP}} & \rotatebox{90}{\textbf{RTE}} & \rotatebox{90}{\textbf{SST-2}} & \rotatebox{90}{\textbf{STS-B}} & \rotatebox{90}{\textbf{Średnia}} \\
    \hline
    \multicolumn{12}{| l |}{\textbf{RoBERTa-base}} \\
    \hline
    0.95 & 91.91 & 59.83 & 83.43 & 84.23 & 91.13 & 91.40 & 85.25 & 76.49 & 95.40 & 90.84 & 84.22 \\
    \hline
    \multicolumn{12}{| l |}{\textbf{RoBERTa-large}} \\
    \hline
    0.27 & 69.39 & 66.36 & 86.63 & 86.47 & 93.66 & 89.96 & 82.05 & 83.73 & 96.20 & 92.14 & 86.36 \\
    \hline
    \multicolumn{12}{| l |}{\textbf{BERT-base-cased}} \\
    \hline
    2.36 & 172.10 & 59.40 & 81.13 & 81.28 & 89.98 & 89.64 & 84.31 & 70.16 & 92.17 & 89.71 & 81.98 \\
    \hline
    \multicolumn{12}{| l |}{\textbf{BERT-base-uncased}} \\
    \hline
    2.33 & 804.25 & 58.88 & 81.68 & 82.35 & 89.29 & 91.08 & 85.80 & 69.62 & 92.41 & 89.36 & 82.27 \\
    \hline
    \multicolumn{12}{| l |}{\textbf{BERT-large-cased}} \\
    \hline
    2.89 & 125.73 & 64.46 & 82.07 & 83.38 & 91.26 & 90.17 & 81.12 & 73.78 & 93.10 & 89.81 & 83.24 \\
    \hline
    \multicolumn{12}{| l |}{\textbf{BERT-large-uncased}} \\
    \hline
    2.82 & 670.67 & 62.26 & 84.35 & 84.43 & 89.19 & 91.08 & 81.69 & 76.49 & 93.44 & 90.11 & 83.67 \\
    \hline
    \multicolumn{12}{| l |}{\textbf{BERT-tiny-uncased}} \\
    \hline
    1.06 & 7540.61 & - & 67.50 & 68.57 & 81.78 & 78.43 & 78.86 & 63.47 & 80.78 & 81.84 & 75.15 \\
    \hline
    \multicolumn{12}{| l |}{\textbf{BERT-mini-uncased}} \\
    \hline
    1.70 & 2714.98 & 24.08 & 74.10 & 75.50 & 84.05 & 84.54 & 81.50 & 66.37 & 86.31 & 85.99 & 73.60 \\
    \hline
    \multicolumn{12}{| l |}{\textbf{BERT-small-uncased}} \\
    \hline
    1.70 & 1577.66 & 38.71 & 76.08 & 76.93 & 85.03 & 86.53 & 83.11 & 64.56 & 88.15 & 87.13 & 76.25 \\
    \hline
    \multicolumn{12}{| l |}{\textbf{BERT-medium-uncased}} \\
    \hline
    1.70 & 1260.64 & 45.10 & 79.98 & 80.62 & 86.71 & 88.83 & 83.58 & 63.83 & 90.22 & 88.37 & 78.58 \\
    \hline
    \multicolumn{12}{| l |}{\textbf{DistilRoBERTa-base}} \\
    \hline
    0.68 & 179.69 & 55.97 & 80.45 & 80.98 & 89.90 & 90.51 & 84.63 & 68.17 & 92.87 & 88.44 & 81.32 \\
    \hline
    \multicolumn{12}{| l |}{\textbf{DistilBERT-base-cased}} \\
    \hline
    2.56 & 494.41 & 46.71 & 78.79 & 80.30 & 88.32 & 87.41 & 84.61 & 58.05 & 91.14 & 84.75 & 77.79 \\
    \hline
    \multicolumn{12}{| l |}{\textbf{DistilBERT-base-uncased}} \\
    \hline
    2.12 & 1303.64 & 54.15 & 80.49 & 81.31 & 89.07 & 88.41 & 84.17 & 64.92 & 90.45 & 86.98 & 79.99 \\
    \hline
    \multicolumn{12}{| l |}{\textbf{ALBERT-base}} \\
    \hline
    2.74 & 1575.85 & 54.30 & 79.16 & 79.51 & 91.17 & 90.73 & 83.67 & 73.24 & 92.17 & 90.67 & 81.62 \\
    \hline
    \multicolumn{12}{| l |}{\textbf{ALBERT-large}} \\
    \hline
    1.30 & 933.39 & 56.03 & 80.07 & 80.65 & 92.82 & 88.77 & 80.41 & 81.19 & 94.71 & 91.12 & 82.86 \\
    \hline
    \multicolumn{12}{| l |}{\textbf{MobileBERT-uncased}} \\
    \hline
    2.13 & 913.53 & 50.65 & 82.19 & 82.49 & 89.75 & 91.02 & 86.50 & 64.92 & 90.79 & 87.46 & 80.64 \\
    \hline
    \multicolumn{12}{| l |}{\textbf{FinBERT}} \\
    \hline
    3.01 & 3527.82 & 33.12 & 77.41 & 78.35 & 86.73 & 85.87 & 80.74 & 63.11 & 87.57 & 85.79 & 75.41 \\
    \hline
    \multicolumn{12}{| l |}{\textbf{SciBERT-uncased}} \\
    \hline
    1.69 & 1681.68 & 41.22 & 80.95 & 81.16 & 90.78 & 88.69 & 81.98 & 67.45 & 89.76 & 87.95 & 78.88 \\
    \hline
    \multicolumn{12}{| l |}{\textbf{SciBERT-cased}} \\
    \hline
    1.80 & 2072.33 & 37.13 & 79.71 & 80.11 & 89.48 & 89.05 & 82.03 & 64.56 & 89.76 & 88.50 & 77.81 \\
    \hline
    \multicolumn{12}{| l |}{\textbf{BioMed-RoBERTa-base}} \\
    \hline
    1.16 & 312.17 & 54.22 & 84.06 & 84.45 & 90.75 & 91.43 & 84.75 & 73.60 & 92.52 & 90.11 & 82.88 \\
    \hline
    \multicolumn{12}{| l |}{\textbf{ClinicalBERT}} \\
    \hline
    2.21 & 4443.60 & 41.40 & 79.02 & 80.76 & 88.52 & 87.42 & 85.02 & 63.83 & 89.87 & 87.98 & 78.20 \\
    \hline
    \multicolumn{12}{| l |}{\textbf{CodeBERT-base}} \\
    \hline
    1.62 & 1174.66 & 40.12 & 80.45 & 81.55 & 87.39 & 88.64 & 84.53 & 63.83 & 91.14 & 87.86 & 78.39 \\
    \hline
    \multicolumn{12}{| l |}{\textbf{XLM-RoBERTa-base}} \\
    \hline
    9.40 & 193.88 & 52.73 & 79.21 & 80.54 & 91.26 & 89.90 & 83.75 & 70.71 & 93.10 & 88.80 & 81.11 \\
    \hline
    \multicolumn{12}{| l |}{\textbf{XLM-RoBERTa-large}} \\
    \hline
    0.90 & 138.83 & 59.20 & 83.74 & 83.86 & 81.22 & 88.61 & 81.75 & 81.56 & 95.28 & 90.94 & 82.91 \\
    \hline
    \multicolumn{12}{| l |}{\textbf{BERT-base-multilingual-uncased}} \\
    \hline
    2.19 & 1477.05 & 44.39 & 79.40 & 80.44 & 90.05 & 88.82 & 84.10 & 70.16 & 91.25 & 88.98 & 79.73 \\
    \hline
    \multicolumn{12}{| l |}{\textbf{BERT-base-multilingual-cased}} \\
    \hline
    2.08 & 635.84 & 38.71 & 79.25 & 80.34 & 90.53 & 90.31 & 78.39 & 72.88 & 89.99 & 88.96 & 78.82 \\
    \hline
    \multicolumn{12}{| l |}{\textbf{Longformer-base}} \\
    \hline
    1.06 & - & 60.50 & 84.50 & 84.70 & 92.74 & 91.76 & 80.22 & 76.49 & 94.48 & 91.10 & 84.06 \\
    \hline
    \multicolumn{12}{| l |}{\textbf{Longformer-large}} \\
    \hline
    0.32 & - & 62.44 & 86.64 & 86.59 & 81.22 & 90.48 & 82.40 & 69.98 & 96.43 & 91.89 & 83.12 \\
    \hline
    \multicolumn{12}{| l |}{\textbf{CamemBERT-base}} \\
    \hline
    1.61 & 3469.33 & - & 78.93 & 79.14 & 88.42 & 87.92 & 84.74 & 69.98 & 88.15 & 85.71 & 82.87 \\
    \hline
    \multicolumn{12}{| l |}{\textbf{PolishRoBERT-base}} \\
    \hline
    0.59 & 12559.89 & - & 72.44 & 73.32 & 89.19 & 83.16 & 82.54 & 66.37 & 85.04 & 84.79 & 79.61 \\
    \hline
    \multicolumn{12}{| l |}{\textbf{German-BERT-base-cased}} \\
    \hline
    2.41 & 27859.71 & - & 73.26 & 74.12 & 86.69 & 82.63 & 78.28 & 62.39 & 86.31 & 84.52 & 78.52 \\
    \hline
    \multicolumn{12}{| l |}{\textbf{GPT-2-base}} \\
    \hline
    3.67 & 4700.32 & 44.97 & 81.01 & 81.92 & 86.61 & 87.79 & 85.47 & 64.56 & 92.17 & 85.94 & 78.94 \\
    \hline
    \multicolumn{12}{| l |}{\textbf{GPT-2-medium}} \\
    \hline
    3.46 & 2250.94 & 54.51 & 84.71 & 84.98 & 87.89 & 90.43 & 87.17 & 71.07 & 94.25 & 89.00 & 82.67 \\
    \hline
    \multicolumn{12}{| l |}{\textbf{GPT-Neo-125M}} \\
    \hline
    3.74 & 4373.95 & 41.85 & 78.83 & 80.07 & 83.54 & 86.09 & 83.10 & 65.64 & 89.41 & 83.52 & 76.89 \\
    \hline
    \multicolumn{12}{| l |}{\textbf{Pythia-70M}} \\
    \hline
    4.07 & 7722.04 & - & 69.19 & 70.47 & 82.89 & 79.83 & 80.78 & 64.56 & 87.11 & 78.17 & 76.62 \\
    \hline
    \multicolumn{12}{| l |}{\textbf{Pythia-70M-deduped}} \\
    \hline
    4.04 & 8823.05 & 21.64 & 72.54 & 73.91 & 82.70 & 79.79 & 79.25 & 62.03 & 87.23 & 80.66 & 71.08 \\
    \hline
    \multicolumn{12}{| l |}{\textbf{Pythia-160M}} \\
    \hline
    3.71 & 5102.75 & 31.73 & 74.12 & 75.39 & 84.05 & 83.42 & 76.84 & 66.00 & 91.02 & 86.11 & 74.30 \\
    \hline
    \multicolumn{12}{| l |}{\textbf{Pythia-160M-deduped}} \\
    \hline
    3.66 & 5450.90 & 35.84 & 74.61 & 75.46 & 84.47 & 84.10 & 80.36 & 67.45 & 89.64 & 86.47 & 75.38 \\
    \hline
    \multicolumn{12}{| l |}{\textbf{Pythia-410M}} \\
    \hline
    3.37 & 3613.64 & 42.73 & 77.61 & 78.58 & 87.73 & 87.10 & 80.90 & 68.90 & 92.52 & 88.34 & 78.27 \\
    \hline
    \multicolumn{12}{| l |}{\textbf{Pythia-410M-deduped}} \\
    \hline
    3.36 & 3927.46 & 48.74 & 77.22 & 78.91 & 86.87 & 85.67 & 79.40 & 70.16 & 92.64 & 88.73 & 78.70 \\
    \hline
    \multicolumn{12}{| l |}{\textbf{OPT-125M}} \\
    \hline
    4.21 & 2021.62 & 52.17 & 72.66 & 73.48 & 68.28 & 87.12 & 81.36 & 58.59 & 91.94 & 87.77 & 74.82 \\
    \hline
    \multicolumn{12}{| l |}{\textbf{OPT-350M}} \\
    \hline
    4.08 & 1767.23 & 53.08 & 74.75 & 76.76 & 85.67 & 85.96 & 78.83 & 70.52 & 93.67 & 88.11 & 78.60 \\
    \hline
    \multicolumn{12}{| l |}{\textbf{Cerebras-GPT-111M}} \\
    \hline
    4.11 & 7638.67 & 31.96 & 74.33 & 75.46 & 84.72 & 83.43 & 78.77 & 65.64 & 87.57 & 82.63 & 73.83 \\
    \hline
    \multicolumn{12}{| l |}{\textbf{Cerebras-GPT-256M}} \\
    \hline
    3.83 & 5563.25 & 39.68 & 74.18 & 75.73 & 85.37 & 84.48 & 77.39 & 68.17 & 90.56 & 85.06 & 75.62 \\
    \hline
    \multicolumn{12}{| l |}{\textbf{DistilGPT-2}} \\
    \hline
    3.95 & 9714.72 & 33.24 & 78.16 & 79.47 & 86.84 & 86.25 & 82.24 & 66.37 & 89.99 & 81.49 & 76.01 \\
    \hline
    \multicolumn{12}{| l |}{\textbf{BioGPT}} \\
    \hline
    3.92 & 9377.07 & 30.67 & 76.87 & 78.64 & 85.99 & 87.76 & 85.41 & 62.03 & 89.99 & 87.19 & 76.06 \\
    \hline
    \multicolumn{12}{| l |}{\textbf{GPT-fr-small}} \\
    \hline
    4.60 & 38199.70 & 20.34 & 72.28 & 72.88 & 85.76 & 83.01 & 80.92 & 63.83 & 83.43 & 79.54 & 71.33 \\
    \hline
    \multicolumn{12}{| l |}{\textbf{PolishGPT-2-small}} \\
    \hline
    3.66 & 79278.56 & - & 68.54 & 70.03 & 84.77 & 80.90 & 72.29 & 62.21 & 82.74 & 81.66 & 75.39 \\
    \hline
    \multicolumn{12}{| l |}{\textbf{T5-small}} \\
    \hline
    9.02 & 782.87 & 25.67 & 80.70 & 81.81 & 87.71 & 90.43 & 84.11 & 67.63 & 90.68 & 85.03 & 77.09 \\
    \hline
    \multicolumn{12}{| l |}{\textbf{T5-base}} \\
    \hline
    14.95 & 274.69 & 57.78 & 86.71 & 86.78 & 91.67 & 93.15 & 88.14 & 81.19 & 94.59 & 89.51 & 85.50 \\
    \hline
    \multicolumn{12}{| l |}{\textbf{T5-small-v1.1}} \\
    \hline
    11.32 & 282303.55 & 1.20 & 77.97 & 78.68 & - & 83.46 & 72.46 & 52.62 & 87.69 & 4.55 & 57.33 \\
    \hline
    \multicolumn{12}{| l |}{\textbf{T5-base-v1.1}} \\
    \hline
    49.56 & 267972.65 & 2.60 & 87.30 & 87.13 & 29.78 & 91.07 & 85.89 & 52.62 & 92.87 & 2.00 & 59.03 \\
    \hline
    \multicolumn{12}{| l |}{\textbf{T5-small-v1.1-lm-adapt}} \\
    \hline
    3.13 & 233990.72 & 12.43 & 79.51 & 80.47 & 81.22 & 85.02 & 82.20 & 61.66 & 90.45 & 31.70 & 67.19 \\
    \hline
    \multicolumn{12}{| l |}{\textbf{T5-base-v1.1-lm-adapt}} \\
    \hline
    5.62 & 63737.13 & 41.41 & 87.68 & 87.44 & 84.34 & 91.41 & 86.85 & 67.81 & 94.36 & 87.34 & 80.96 \\
    \hline
    \multicolumn{12}{| l |}{\textbf{T5-efficient-tiny}} \\
    \hline
    18.00 & 418979.06 & 5.11 & 70.03 & 71.43 & - & 80.44 & 72.68 & 54.79 & 82.05 & 9.96 & 55.81 \\
    \hline
    \multicolumn{12}{| l |}{\textbf{T5-efficient-mini}} \\
    \hline
    15.98 & 510519.38 & - & 75.21 & 75.84 & - & 84.07 & 66.47 & 52.62 & 84.58 & 13.18 & 64.57 \\
    \hline
    \multicolumn{12}{| l |}{\textbf{T5-efficient-small}} \\
    \hline
    6.61 & 277887.45 & 0.43 & 78.77 & 79.09 & 81.22 & 86.63 & 70.01 & 58.77 & 89.18 & 55.16 & 66.58 \\
    \hline
    \multicolumn{12}{| l |}{\textbf{T5-efficient-base}} \\
    \hline
    11.84 & 124430.99 & 2.01 & 84.20 & 84.33 & 22.42 & 90.28 & 86.17 & 63.47 & 92.06 & 65.73 & 65.63 \\
    \hline
    \multicolumn{12}{| l |}{\textbf{Switch-base-8}} \\
    \hline
    22.21 & 349.97 & 47.46 & 86.44 & 86.44 & 81.29 & 91.14 & 87.21 & 62.39 & 94.25 & 86.15 & 80.31 \\
    \hline
    \multicolumn{12}{| l |}{\textbf{FLAN-T5-small}} \\
    \hline
    2.19 & 324604.41 & 4.94 & 80.85 & 81.18 & 82.52 & 90.62 & 79.46 & 68.17 & 91.25 & 58.00 & 70.78 \\
    \hline
    \multicolumn{12}{| l |}{\textbf{FLAN-T5-base}} \\
    \hline
    1.60 & 118104.57 & 43.36 & 87.74 & 87.44 & 86.68 & 93.02 & 81.74 & 82.64 & 94.36 & 89.05 & 82.89 \\
    \hline
    \multicolumn{12}{| l |}{\textbf{mT5-small}} \\
    \hline
    27.90 & 3976.32 & 1.54 & 75.06 & 76.22 & - & 84.77 & 81.16 & 52.62 & 59.84 & 83.72 & 64.37 \\
    \hline
    \multicolumn{12}{| l |}{\textbf{mT5-base}} \\
    \hline
    14.82 & 2491.98 & 4.50 & 82.85 & 83.76 & 47.03 & 90.02 & 85.38 & 57.69 & 89.30 & 85.67 & 69.58 \\
    \hline
    \multicolumn{12}{| l |}{\textbf{ByT5-small}} \\
    \hline
    11.64 & 584584.35 & 4.94 & 79.55 & 80.68 & 81.22 & 87.83 & 84.50 & 57.69 & 62.83 & 3.99 & 60.36 \\
    \hline
    \multicolumn{12}{| l |}{\textbf{ByT5-base}} \\
    \hline
    2.70 & 855967.36 & - & 83.29 & 83.91 & 81.22 & 91.52 & 87.94 & 55.52 & 90.45 & 80.41 & 81.78 \\
    \hline
    \multicolumn{12}{| l |}{\textbf{LongT5-TGlobal-base}} \\
    \hline
    0.53 & 211414.92 & - & 85.26 & 85.80 & 82.02 & 89.95 & 86.82 & 60.22 & 92.98 & 83.96 & 83.38 \\
    \hline
    \multicolumn{12}{| l |}{\textbf{LongT5-Local-base}} \\
    \hline
    380.89 & 1008375.97 & - & 84.19 & 84.51 & 82.11 & 85.77 & 82.28 & 59.86 & 91.60 & 79.53 & 81.23 \\
    \hline
\end{longtable}

